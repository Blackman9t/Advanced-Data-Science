{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "('0.24.1', '1.15.4')"
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import pandas as pd\nimport numpy as np\n\npd.__version__, np.__version__"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Why did we import pandas? Because pandas is the defacto dataframe manipulation library of python and we are about downlaoading a data set.**"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's fetch the zipped file from github and unzip it to get the full bank details using !wget"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-04-14 09:39:56--  https://github.com/Blackman9t/Machine_Learning/blob/master/bank-additional.zip?raw=true\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github.com/Blackman9t/Machine_Learning/raw/master/bank-additional.zip [following]\n--2020-04-14 09:39:56--  https://github.com/Blackman9t/Machine_Learning/raw/master/bank-additional.zip\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/bank-additional.zip [following]\n--2020-04-14 09:39:56--  https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/bank-additional.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 444572 (434K) [application/zip]\nSaving to: \u2018bank_data.zip\u2019\n\n100%[======================================>] 444,572     --.-K/s   in 0.04s   \n\n2020-04-14 09:39:56 (11.3 MB/s) - \u2018bank_data.zip\u2019 saved [444572/444572]\n\nArchive:  bank_data.zip\n   creating: bank-additional/\n  inflating: bank-additional/.DS_Store  \n   creating: __MACOSX/\n   creating: __MACOSX/bank-additional/\n  inflating: __MACOSX/bank-additional/._.DS_Store  \n  inflating: bank-additional/.Rhistory  \n  inflating: bank-additional/bank-additional-full.csv  \n  inflating: bank-additional/bank-additional-names.txt  \n  inflating: bank-additional/bank-additional.csv  \n  inflating: __MACOSX/._bank-additional  \n"
                }
            ],
            "source": "!wget https://github.com/Blackman9t/Machine_Learning/blob/master/bank-additional.zip?raw=true -O bank_data.zip; unzip bank_data.zip; rm bank_data.zip;"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "bank-additional.csv  bank-additional-full.csv  bank-additional-names.txt\r\n"
                }
            ],
            "source": "# Let's see the files in the folder\n! ls bank-additional"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Next, let's read the file to a pandas data frame and remember to ask pandas sep elements by semicolon, not comma. This file is sep by semicolon."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>basic.4y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>basic.6y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>",
                        "text/plain": "   age        job  marital    education  default housing loan    contact  \\\n0   56  housemaid  married     basic.4y       no      no   no  telephone   \n1   57   services  married  high.school  unknown      no   no  telephone   \n2   37   services  married  high.school       no     yes   no  telephone   \n3   40     admin.  married     basic.6y       no      no   no  telephone   \n4   56   services  married  high.school       no      no  yes  telephone   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         0  nonexistent          1.1   \n1   may         mon  ...         1    999         0  nonexistent          1.1   \n2   may         mon  ...         1    999         0  nonexistent          1.1   \n3   may         mon  ...         1    999         0  nonexistent          1.1   \n4   may         mon  ...         1    999         0  nonexistent          1.1   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          93.994          -36.4      4.857       5191.0  no  \n1          93.994          -36.4      4.857       5191.0  no  \n2          93.994          -36.4      4.857       5191.0  no  \n3          93.994          -36.4      4.857       5191.0  no  \n4          93.994          -36.4      4.857       5191.0  no  \n\n[5 rows x 21 columns]"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To know more about the data, see the [data-dictionary-link](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(41188, 21)\n"
                }
            ],
            "source": "print(df.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Look at the two code cells below and try to guess what they do..."
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Using TensorFlow backend.\n"
                }
            ],
            "source": "import keras\nfrom keras.layers import Flatten, Dense\nfrom keras.models import Sequential"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
                }
            ],
            "source": "model = Sequential([Flatten(input_shape=(28,28)),\n                   Dense(128, activation='relu'),\n                   Dense(10, activation='softmax')])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The first code-cell above imports the keras library for deep_learning (neural network computation). It also imports two layers:-Dense and Flatten, and finally imports a Sequential model.\n<br>The second code-cell builds the model by stacking the layers. The Flatten layer takes the inputs of shape (28,28) and flattens them into a vector of 28*28 elements. This is the first layer or the input layer of the neural network. <br>The first Dense layer is the hidden layer and has 128 nodes or neurons each receiving inputs from each input layer. This Dense layer activates the Relu (Rectified Linear unit) function on the neurons. <br>Then the second Dense layer has 10 neurons representing the 10 possible outcomes of the model. It activates the Softmax function that returns the probabilities of each possible outcome. <br>Obviously the outcome with the greatest probability score becomes the model's prediction.  "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "let's keep building the deep learning neural network model."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 4us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 2s 0us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 1s 0us/step\n"
                }
            ],
            "source": "# let's load the data ansd split into training and testing sets with labels.\nfashion_mnist = keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "train_images shape is (60000, 28, 28)\ntrain_labels shape is (60000,)\ntest_images shape is (10000, 28, 28)\ntest_labels shape is (10000,)\n"
                }
            ],
            "source": "print('train_images shape is {}'.format(train_images.shape))\nprint('train_labels shape is {}'.format(train_labels.shape))\nprint('test_images shape is {}'.format(test_images.shape))\nprint('test_labels shape is {}'.format(test_labels.shape))"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# let's define class names for our target outputs\nclass_names = ['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle_boot']"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# let's see the unique classes in our target\nnp.unique(train_labels)"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "train_images = train_images/255\ntest_images = test_images/255"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# let's compile the model with an optimizer, loss-func and a metric for evaluation.\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n60000/60000 [==============================] - 36s 608us/step - loss: 0.4971 - acc: 0.8261\nEpoch 2/10\n60000/60000 [==============================] - 43s 712us/step - loss: 0.3743 - acc: 0.8647\nEpoch 3/10\n60000/60000 [==============================] - 35s 583us/step - loss: 0.3363 - acc: 0.8774\nEpoch 4/10\n60000/60000 [==============================] - 34s 569us/step - loss: 0.3104 - acc: 0.8867\nEpoch 5/10\n60000/60000 [==============================] - 38s 635us/step - loss: 0.2950 - acc: 0.8917\nEpoch 6/10\n60000/60000 [==============================] - 36s 593us/step - loss: 0.2799 - acc: 0.8954\nEpoch 7/10\n60000/60000 [==============================] - 35s 591us/step - loss: 0.2686 - acc: 0.9012\nEpoch 8/10\n60000/60000 [==============================] - 42s 708us/step - loss: 0.2564 - acc: 0.9046\nEpoch 9/10\n60000/60000 [==============================] - 37s 611us/step - loss: 0.2477 - acc: 0.9072\nEpoch 10/10\n60000/60000 [==============================] - 43s 719us/step - loss: 0.2398 - acc: 0.9108\n"
                },
                {
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7fdc8580ee80>"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Now let's train the model with the data\nmodel.fit(train_images, train_labels, epochs=10, verbose=1)"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "10000/10000 [==============================] - 2s 217us/step\n"
                }
            ],
            "source": "# Let's evaluate our model on the test data set\ntest_loss, test_accy = model.evaluate(test_images, test_labels, verbose=1)"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Test Accuracy:  0.88\n"
                }
            ],
            "source": "print('Test Accuracy: ', test_accy)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "89% accuracy on test data ain't bad atall. But it's always best to be somewhat skeptical of our model to protect ourselves from confirmation biases."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## LALE with REGRESSION EXAMPLE"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**About lale:**\n\nLale is a Python library for semi-automated data science. Lale makes it easy to automatically select algorithms and tune hyperparameters of pipelines that are compatible with scikit-learn, in a type-safe fashion. If you are a data scientist who wants to experiment with automated machine learning, this library is for you! Lale adds value beyond scikit-learn along three dimensions: automation, correctness checks, and interoperability. For automation, Lale provides a consistent high-level interface to existing pipeline search tools including GridSearchCV, SMAC, and Hyperopt. For correctness checks, Lale uses JSON Schema to catch mistakes when there is a mismatch between hyperparameters and their type, or between data and operators. And for interoperability, Lale has a growing library of transformers and estimators from popular libraries such as scikit-learn, XGBoost, PyTorch etc. Lale can be installed just like any other Python package and can be edited with off-the-shelf Python tools such as Jupyter notebooks."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting lale\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/47/ab5e8dbc0e73fe051d1ab84f8a3a072846907629f9daddb01fd79725dfbd/lale-0.3.5-py3-none-any.whl (530kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 532kB 7.4MB/s eta 0:00:01\n\u001b[?25hCollecting hyperopt==0.2.3 (from lale)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/11/8bbbb5edb78c40a2bd0f6b730e3dc0f29ffbaea9a59520eb9622951e9151/hyperopt-0.2.3-py3-none-any.whl (1.9MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.9MB 15.8MB/s eta 0:00:01\n\u001b[?25hCollecting jsonsubschema (from lale)\n  Downloading https://files.pythonhosted.org/packages/31/bb/b2bba9f5c7a4e93917c39d744b1093846143cfec021d41ff5a9bf5c05bb5/jsonsubschema-0.0.1-py3-none-any.whl\nRequirement already satisfied: astunparse in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.6.2)\nRequirement already satisfied: h5py in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (2.9.0)\nCollecting graphviz (from lale)\n  Downloading https://files.pythonhosted.org/packages/f5/74/dbed754c0abd63768d3a7a7b472da35b08ac442cf87d73d5850a6f32391e/graphviz-0.13.2-py2.py3-none-any.whl\nCollecting xgboost (from lale)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/91/551d37ba472bcbd70a25e667acc65a18a9d053657b13afcf0f87aa24d7bb/xgboost-1.0.2-py3-none-manylinux1_x86_64.whl (109.7MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 109.8MB 53.9MB/s eta 0:00:01    |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 76.9MB 49.8MB/s eta 0:00:01\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f      | 86.4MB 49.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: decorator in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (4.3.2)\nRequirement already satisfied: pandas<=0.25.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.24.1)\nRequirement already satisfied: scikit-learn==0.20.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.20.3)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.15.4)\nCollecting lightgbm (from lale)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.2MB 36.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jsonschema in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (2.6.0)\nRequirement already satisfied: scipy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.2.0)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (1.12.0)\nRequirement already satisfied: networkx==2.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (2.2)\nRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (0.17.1)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (4.31.1)\nRequirement already satisfied: cloudpickle in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (0.7.0)\nCollecting python-intervals (from jsonsubschema->lale)\n  Downloading https://files.pythonhosted.org/packages/4e/51/b29570d4a820610be14d232aec77e6f0c66bca3d400f4903e98cc00012cb/python_intervals-1.10.0.post1-py2.py3-none-any.whl\nCollecting greenery (from jsonsubschema->lale)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/69/2c2a77e7034650954e54144ea2b88ec8742a81ac69fbe84da319e0e9112c/greenery-3.1.zip (40kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40kB 20.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from astunparse->lale) (0.32.3)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->lale) (2018.9)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->lale) (2.7.5)\nBuilding wheels for collected packages: greenery\n  Building wheel for greenery (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/af/89/c9/732423b6882ac44308df31022ec106ac759e2f6709a4c7efd8\nSuccessfully built greenery\nInstalling collected packages: hyperopt, python-intervals, greenery, jsonsubschema, graphviz, xgboost, lightgbm, lale\nSuccessfully installed graphviz-0.13.2 greenery-3.1 hyperopt-0.2.3 jsonsubschema-0.0.1 lale-0.3.5 lightgbm-2.3.1 python-intervals-1.10.0.post1 xgboost-1.0.2\nlale installed success!\n"
                }
            ],
            "source": "# first let's install lale\n\ntry:\n    !pip install lale\n    print('lale installed success!')\nexcept Exception as e:\n    print(e)"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "# now let's import sklearn and the lale libraries\n\nimport sklearn as sk\nimport lale"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /home/dsxuser/scikit_learn_data\nINFO:sklearn.datasets.california_housing:Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /home/dsxuser/scikit_learn_data\n"
                }
            ],
            "source": "# let's load the carlifornia housing data set\ncal_housing = sk.datasets.fetch_california_housing()\n\n# Let's load it to a pandas data frame\nx = pd.DataFrame(cal_housing.data, columns = cal_housing.feature_names)\ny = cal_housing.target"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'numpy.ndarray'>\n"
                },
                {
                    "data": {
                        "text/plain": "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "print(type(y))\ny"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's see x and y"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.3252</td>\n      <td>41.0</td>\n      <td>6.984127</td>\n      <td>1.023810</td>\n      <td>322.0</td>\n      <td>2.555556</td>\n      <td>37.88</td>\n      <td>-122.23</td>\n      <td>4.526</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.3014</td>\n      <td>21.0</td>\n      <td>6.238137</td>\n      <td>0.971880</td>\n      <td>2401.0</td>\n      <td>2.109842</td>\n      <td>37.86</td>\n      <td>-122.22</td>\n      <td>3.585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.2574</td>\n      <td>52.0</td>\n      <td>8.288136</td>\n      <td>1.073446</td>\n      <td>496.0</td>\n      <td>2.802260</td>\n      <td>37.85</td>\n      <td>-122.24</td>\n      <td>3.521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.6431</td>\n      <td>52.0</td>\n      <td>5.817352</td>\n      <td>1.073059</td>\n      <td>558.0</td>\n      <td>2.547945</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n      <td>3.413</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.8462</td>\n      <td>52.0</td>\n      <td>6.281853</td>\n      <td>1.081081</td>\n      <td>565.0</td>\n      <td>2.181467</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n      <td>3.422</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n\n   Longitude      0  \n0    -122.23  4.526  \n1    -122.22  3.585  \n2    -122.24  3.521  \n3    -122.25  3.413  \n4    -122.25  3.422  "
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pd.concat([x.head(), pd.DataFrame(y).head()],axis=1)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's make a Pipeline based on this data, using PCA to reduce the dimensionality of the data."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.preprocessing import Normalizer\nfrom sklearn.tree import DecisionTreeRegressor as Tree\nfrom lale.lib.lale import Hyperopt\nimport lale.helpers\nlale.wrap_imported_operators()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We use the Regression-Based decision tre since we can see that the y value is a continuous flow"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "pipe = Normalizer >> Tree"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"175pt\" height=\"44pt\"\n viewBox=\"0.00 0.00 175.03 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 171.0256,-40 171.0256,4 -4,4\"/>\n</a>\n</g>\n<!-- normalizer -->\n<g id=\"node1\" class=\"node\">\n<title>normalizer</title>\n<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\" xlink:title=\"normalizer = Normalizer\">\n<ellipse fill=\"#7ec0ee\" stroke=\"#000000\" cx=\"38.5128\" cy=\"-18\" rx=\"38.5256\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"38.5128\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Normalizer</text>\n</a>\n</g>\n</g>\n<!-- tree -->\n<g id=\"node2\" class=\"node\">\n<title>tree</title>\n<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\" xlink:title=\"tree = Tree\">\n<ellipse fill=\"#7ec0ee\" stroke=\"#000000\" cx=\"140.0256\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"140.0256\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Tree</text>\n</a>\n</g>\n</g>\n<!-- normalizer&#45;&gt;tree -->\n<g id=\"edge1\" class=\"edge\">\n<title>normalizer&#45;&gt;tree</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.18,-18C85.532,-18 94.3477,-18 102.6492,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.8158,-21.5001 112.8158,-18 102.8157,-14.5001 102.8158,-21.5001\"/>\n</g>\n</g>\n</svg>\n",
                        "text/plain": "<graphviz.dot.Digraph at 0x7f0f2c2f6fd0>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "pipe.visualize()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's split the data into 80% training and 20% testing sets"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split(x,y, test_size=0.2, random_state=0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's train a Tree based model using lale auto-configure"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "pipe_trainable = Hyperopt(estimator = pipe, cv = 3, max_evals = 10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 204, in cross_val_score_track_trials\n    score_value  = scorer(trained, X_test, y_test, **args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 176, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 88, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 0.31944725103976734, 'min_samples_leaf': 0.04383515702806606, 'min_samples_split': 17, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " 10%|\u2588         | 1/10 [00:00<00:02,  3.42trial/s, best loss=?]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 204, in cross_val_score_track_trials\n    score_value  = scorer(trained, X_test, y_test, **args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 176, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 88, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'mae', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 0.4671053194354385, 'min_samples_split': 0.36658561415688923, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " 20%|\u2588\u2588        | 2/10 [00:00<00:02,  2.91trial/s, best loss=?]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 204, in cross_val_score_track_trials\n    score_value  = scorer(trained, X_test, y_test, **args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 176, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 88, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l1'}, {'criterion': 'friedman_mse', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 0.15867095384324573, 'min_samples_split': 0.4428244859166224, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " 30%|\u2588\u2588\u2588       | 3/10 [00:01<00:02,  3.00trial/s, best loss=?]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 204, in cross_val_score_track_trials\n    score_value  = scorer(trained, X_test, y_test, **args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 176, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 88, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'mae', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 19, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:04<00:08,  1.41s/trial, best loss=?]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 204, in cross_val_score_track_trials\n    score_value  = scorer(trained, X_test, y_test, **args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 176, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py\", line 88, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l1'}, {'criterion': 'mse', 'max_depth': 4, 'max_features': 0.8027647811563103, 'min_samples_leaf': 12, 'min_samples_split': 0.09421706508431472, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:05<00:05,  1.11s/trial, best loss=?]"
                }
            ],
            "source": "pipe_trained = pipe_trainable.fit(train_x, train_y)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "# tree_trained = tree_plan.auto_configure(train_x, train_y, optimizer= Hyperopt, cv=3, scoring='r2') "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**INTUITION:**\n    \nThe reason why we use PCA is because we want to reduce the dimensionality of the data.\n<br>Doing this allows us to compact the variance from the input data into as few dimensions as possible, Curse of Dimensionality.\n<br>We use a Tree Regressor because we want to understand the impact the independent variables have on the dependent variable. Also, the dependent variable is continuous and fit for a Regressor algorithm."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tree_trained.pretty_print(Ipython_display=True, show_imports=False)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tree_trained.visualize()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import sklearn.metrics\npredicted = tree_trained.predict(test_x)\n# print(f'R2 score {sklearn.metrics.r2_score(test_y, predicted):.2f}')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}