{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\n\npd.__version__, np.__version__",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 1,
                    "data": {
                        "text/plain": "('0.24.1', '1.15.4')"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**Why did we import pandas? Because pandas is the defacto dataframe manipulation library of python and we are about downlaoading a data set.**"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's fetch the zipped file from github and unzip it to get the full bank details using !wget"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget https://github.com/Blackman9t/Machine_Learning/blob/master/bank-additional.zip?raw=true -O bank_data.zip; unzip bank_data.zip; rm bank_data.zip;",
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2020-04-13 21:12:03--  https://github.com/Blackman9t/Machine_Learning/blob/master/bank-additional.zip?raw=true\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github.com/Blackman9t/Machine_Learning/raw/master/bank-additional.zip [following]\n--2020-04-13 21:12:03--  https://github.com/Blackman9t/Machine_Learning/raw/master/bank-additional.zip\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/bank-additional.zip [following]\n--2020-04-13 21:12:03--  https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/bank-additional.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 444572 (434K) [application/zip]\nSaving to: \u2018bank_data.zip\u2019\n\n100%[======================================>] 444,572     --.-K/s   in 0.02s   \n\n2020-04-13 21:12:03 (18.7 MB/s) - \u2018bank_data.zip\u2019 saved [444572/444572]\n\nArchive:  bank_data.zip\nreplace bank-additional/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: ",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Let's see the files in the folder\n! ls bank-additional",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "bank-additional.csv  bank-additional-full.csv  bank-additional-names.txt\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Next, let's read the file to a pandas data frame and remember to ask pandas sep elements by semicolon, not comma. This file is sep by semicolon."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "df = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\ndf.head()",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "   age        job  marital    education  default housing loan    contact  \\\n0   56  housemaid  married     basic.4y       no      no   no  telephone   \n1   57   services  married  high.school  unknown      no   no  telephone   \n2   37   services  married  high.school       no     yes   no  telephone   \n3   40     admin.  married     basic.6y       no      no   no  telephone   \n4   56   services  married  high.school       no      no  yes  telephone   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         0  nonexistent          1.1   \n1   may         mon  ...         1    999         0  nonexistent          1.1   \n2   may         mon  ...         1    999         0  nonexistent          1.1   \n3   may         mon  ...         1    999         0  nonexistent          1.1   \n4   may         mon  ...         1    999         0  nonexistent          1.1   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          93.994          -36.4      4.857       5191.0  no  \n1          93.994          -36.4      4.857       5191.0  no  \n2          93.994          -36.4      4.857       5191.0  no  \n3          93.994          -36.4      4.857       5191.0  no  \n4          93.994          -36.4      4.857       5191.0  no  \n\n[5 rows x 21 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>basic.4y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>basic.6y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "To know more about the data, see the [data-dictionary-link](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#)"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(df.shape)",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "(41188, 21)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Look at the two code cells below and try to guess what they do..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import keras\nfrom keras.layers import Flatten, Dense\nfrom keras.models import Sequential",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Using TensorFlow backend.\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "model = Sequential([Flatten(input_shape=(28,28)),\n                   Dense(128, activation='relu'),\n                   Dense(10, activation='softmax')])",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The first code-cell above imports the keras library for deep_learning (neural network computation). It also imports two layers:-Dense and Flatten, and finally imports a Sequential model.\n<br>The second code-cell builds the model by stacking the layers. The Flatten layer takes the inputs of shape (28,28) and flattens them into a vector of 28*28 elements. This is the first layer or the input layer of the neural network. <br>The first Dense layer is the hidden layer and has 128 nodes or neurons each receiving inputs from each input layer. This Dense layer activates the Relu (Rectified Linear unit) function on the neurons. <br>Then the second Dense layer has 10 neurons representing the 10 possible outcomes of the model. It activates the Softmax function that returns the probabilities of each possible outcome. <br>Obviously the outcome with the greatest probability score becomes the model's prediction.  "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "let's keep building the deep learning neural network model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# let's load the data ansd split into training and testing sets with labels.\nfashion_mnist = keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "print('train_images shape is {}'.format(train_images.shape))\nprint('train_labels shape is {}'.format(train_labels.shape))\nprint('test_images shape is {}'.format(test_images.shape))\nprint('test_labels shape is {}'.format(test_labels.shape))",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "train_images shape is (60000, 28, 28)\ntrain_labels shape is (60000,)\ntest_images shape is (10000, 28, 28)\ntest_labels shape is (10000,)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# let's define class names for our target outputs\nclass_names = ['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle_boot']",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# let's see the unique classes in our target\nnp.unique(train_labels)",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "train_images = train_images/255\ntest_images = test_images/255",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# let's compile the model with an optimizer, loss-func and a metric for evaluation.\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# Now let's train the model with the data\nmodel.fit(train_images, train_labels, epochs=10, verbose=1)",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n60000/60000 [==============================] - 36s 608us/step - loss: 0.4971 - acc: 0.8261\nEpoch 2/10\n60000/60000 [==============================] - 43s 712us/step - loss: 0.3743 - acc: 0.8647\nEpoch 3/10\n60000/60000 [==============================] - 35s 583us/step - loss: 0.3363 - acc: 0.8774\nEpoch 4/10\n60000/60000 [==============================] - 34s 569us/step - loss: 0.3104 - acc: 0.8867\nEpoch 5/10\n60000/60000 [==============================] - 38s 635us/step - loss: 0.2950 - acc: 0.8917\nEpoch 6/10\n60000/60000 [==============================] - 36s 593us/step - loss: 0.2799 - acc: 0.8954\nEpoch 7/10\n60000/60000 [==============================] - 35s 591us/step - loss: 0.2686 - acc: 0.9012\nEpoch 8/10\n60000/60000 [==============================] - 42s 708us/step - loss: 0.2564 - acc: 0.9046\nEpoch 9/10\n60000/60000 [==============================] - 37s 611us/step - loss: 0.2477 - acc: 0.9072\nEpoch 10/10\n60000/60000 [==============================] - 43s 719us/step - loss: 0.2398 - acc: 0.9108\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 13,
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7fdc8580ee80>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Let's evaluate our model on the test data set\ntest_loss, test_accy = model.evaluate(test_images, test_labels, verbose=1)",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "10000/10000 [==============================] - 2s 217us/step\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print('Test Accuracy: ', test_accy)",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Test Accuracy:  0.88\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "89% accuracy on test data ain't bad atall. But it's always best to be somewhat skeptical of our model to protect ourselves from confirmation biases."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## LALE with REGRESSION EXAMPLE"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**About lale:**\n\nLale is a Python library for semi-automated data science. Lale makes it easy to automatically select algorithms and tune hyperparameters of pipelines that are compatible with scikit-learn, in a type-safe fashion. If you are a data scientist who wants to experiment with automated machine learning, this library is for you! Lale adds value beyond scikit-learn along three dimensions: automation, correctness checks, and interoperability. For automation, Lale provides a consistent high-level interface to existing pipeline search tools including GridSearchCV, SMAC, and Hyperopt. For correctness checks, Lale uses JSON Schema to catch mistakes when there is a mismatch between hyperparameters and their type, or between data and operators. And for interoperability, Lale has a growing library of transformers and estimators from popular libraries such as scikit-learn, XGBoost, PyTorch etc. Lale can be installed just like any other Python package and can be edited with off-the-shelf Python tools such as Jupyter notebooks."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# first let's install lale\n\ntry:\n    !pip install lale\n    print('lale installed success!')\nexcept Exception as e:\n    print(e)",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: lale in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.3.5)\nRequirement already satisfied: lightgbm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (2.3.1)\nRequirement already satisfied: jsonsubschema in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.0.1)\nRequirement already satisfied: graphviz in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.13.2)\nRequirement already satisfied: scikit-learn==0.20.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.20.3)\nRequirement already satisfied: scipy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.2.0)\nRequirement already satisfied: xgboost in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.0.2)\nRequirement already satisfied: decorator in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (4.3.2)\nRequirement already satisfied: h5py in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (2.9.0)\nRequirement already satisfied: hyperopt==0.2.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.2.3)\nRequirement already satisfied: astunparse in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.6.2)\nRequirement already satisfied: jsonschema in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (2.6.0)\nRequirement already satisfied: pandas<=0.25.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (0.24.1)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lale) (1.15.4)\nRequirement already satisfied: greenery in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jsonsubschema->lale) (3.1)\nRequirement already satisfied: python-intervals in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jsonsubschema->lale) (1.10.0.post1)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from h5py->lale) (1.12.0)\nRequirement already satisfied: cloudpickle in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (0.7.0)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (4.31.1)\nRequirement already satisfied: networkx==2.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (2.2)\nRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from hyperopt==0.2.3->lale) (0.17.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from astunparse->lale) (0.32.3)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->lale) (2.7.5)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->lale) (2018.9)\nlale installed success!\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# now let's import sklearn and the lale libraries\n\nimport sklearn as sk\nimport lale",
            "execution_count": 17,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# let's load the carlifornia housing data set\ncal_housing = sk.datasets.fetch_california_housing()\n\n# Let's load it to a pandas data frame\nx = pd.DataFrame(cal_housing.data, columns = cal_housing.feature_names)\ny = cal_housing.target",
            "execution_count": 18,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(type(y))\ny",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "<class 'numpy.ndarray'>\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 19,
                    "data": {
                        "text/plain": "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's see x and y"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd.concat([x.head(), pd.DataFrame(y).head()],axis=1)",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 20,
                    "data": {
                        "text/plain": "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n\n   Longitude      0  \n0    -122.23  4.526  \n1    -122.22  3.585  \n2    -122.24  3.521  \n3    -122.25  3.413  \n4    -122.25  3.422  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.3252</td>\n      <td>41.0</td>\n      <td>6.984127</td>\n      <td>1.023810</td>\n      <td>322.0</td>\n      <td>2.555556</td>\n      <td>37.88</td>\n      <td>-122.23</td>\n      <td>4.526</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.3014</td>\n      <td>21.0</td>\n      <td>6.238137</td>\n      <td>0.971880</td>\n      <td>2401.0</td>\n      <td>2.109842</td>\n      <td>37.86</td>\n      <td>-122.22</td>\n      <td>3.585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.2574</td>\n      <td>52.0</td>\n      <td>8.288136</td>\n      <td>1.073446</td>\n      <td>496.0</td>\n      <td>2.802260</td>\n      <td>37.85</td>\n      <td>-122.24</td>\n      <td>3.521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.6431</td>\n      <td>52.0</td>\n      <td>5.817352</td>\n      <td>1.073059</td>\n      <td>558.0</td>\n      <td>2.547945</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n      <td>3.413</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.8462</td>\n      <td>52.0</td>\n      <td>6.281853</td>\n      <td>1.081081</td>\n      <td>565.0</td>\n      <td>2.181467</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n      <td>3.422</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's make a Pipeline based on this data, using PCA to reduce the dimensionality of the data."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.preprocessing import Normalizer\nfrom sklearn.tree import DecisionTreeRegressor as Tree\nfrom lale.lib.lale import Hyperopt\nimport lale.helpers\nlale.wrap_imported_operators()",
            "execution_count": 21,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We use the Regression-Based decision tre since we can see that the y value is a continuous flow"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipe = Normalizer >> Tree",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipe.visualize()",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<graphviz.dot.Digraph at 0x7fdc8422d5c0>",
                        "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"175pt\" height=\"44pt\"\n viewBox=\"0.00 0.00 175.03 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 171.0256,-40 171.0256,4 -4,4\"/>\n</a>\n</g>\n<!-- normalizer -->\n<g id=\"node1\" class=\"node\">\n<title>normalizer</title>\n<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\" xlink:title=\"normalizer = Normalizer\">\n<ellipse fill=\"#7ec0ee\" stroke=\"#000000\" cx=\"38.5128\" cy=\"-18\" rx=\"38.5256\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"38.5128\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Normalizer</text>\n</a>\n</g>\n</g>\n<!-- tree -->\n<g id=\"node2\" class=\"node\">\n<title>tree</title>\n<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\" xlink:title=\"tree = Tree\">\n<ellipse fill=\"#7ec0ee\" stroke=\"#000000\" cx=\"140.0256\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"140.0256\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Tree</text>\n</a>\n</g>\n</g>\n<!-- normalizer&#45;&gt;tree -->\n<g id=\"edge1\" class=\"edge\">\n<title>normalizer&#45;&gt;tree</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.18,-18C85.532,-18 94.3477,-18 102.6492,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.8158,-21.5001 112.8158,-18 102.8157,-14.5001 102.8158,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's split the data into 80% training and 20% testing sets"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\n\ntrain_x, train_y, test_x, test_y = train_test_split(x,y, test_size=0.2, random_state=0)",
            "execution_count": 24,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's train a Tree based model using lale auto-configure"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipe_trainable = Hyperopt(estimator = pipe, cv = 3, max_evals = 10)",
            "execution_count": 25,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "pipe_trained = pipe_trainable.fit(train_x, train_y)",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "\r  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 0.31944725103976734, 'min_samples_leaf': 0.04383515702806606, 'min_samples_split': 17, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 10%|\u2588         | 1/10 [00:00<00:01,  7.62trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'mae', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 0.4671053194354385, 'min_samples_split': 0.36658561415688923, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 20%|\u2588\u2588        | 2/10 [00:00<00:01,  5.45trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l1'}, {'criterion': 'friedman_mse', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 0.15867095384324573, 'min_samples_split': 0.4428244859166224, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 30%|\u2588\u2588\u2588       | 3/10 [00:00<00:01,  6.07trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'mae', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 19, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:00,  6.69trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l1'}, {'criterion': 'mse', 'max_depth': 4, 'max_features': 0.8027647811563103, 'min_samples_leaf': 12, 'min_samples_split': 0.09421706508431472, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:00,  6.26trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l2'}, {'criterion': 'mae', 'max_depth': None, 'max_features': 0.7157132621070329, 'min_samples_leaf': 11, 'min_samples_split': 0.2246343013560524, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:01<00:00,  5.25trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l2'}, {'criterion': 'mae', 'max_depth': 4, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 0.47029117142535803, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  6.12trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'l1'}, {'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 0.1859212366414879, 'min_samples_split': 0.38992854562566237, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  6.81trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'mae', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 19, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'best'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01<00:00,  7.13trial/s, best loss=?]",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "WARNING:lale.lib.lale.hyperopt:Exception caught in Hyperopt:<class 'ValueError'>, Traceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 100, in proc_train_test\n    score, logloss, execution_time = hyperopt_train_test(params, X_train=X_train, y_train=y_train)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 93, in hyperopt_train_test\n    raise e\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\", line 73, in hyperopt_train_test\n    cv_score, logloss, execution_time = cross_val_score_track_trials(trainable, X_train, y_train, cv=self.cv, scoring=self.scoring, args_to_scorer=self.args_to_scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/helpers.py\", line 194, in cross_val_score_track_trials\n    for train, test in cv.split(X, y):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\", line 323, in split\n    X, y, groups = indexable(X, y, groups)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 260, in indexable\n    check_consistent_length(*result)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 235, in check_consistent_length\n    \" samples: %r\" % [int(l) for l in lengths])\nValueError: Found input variables with inconsistent numbers of samples: [16512, 4128]\n with hyperparams: ({'name': 'lale.lib.sklearn.normalizer.Normalizer', 'norm': 'max'}, {'criterion': 'mse', 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 18, 'min_samples_split': 15, 'name': 'lale.lib.sklearn.decision_tree_regressor.Tree', 'splitter': 'random'}), setting status to FAIL\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  4.96trial/s, best loss=?]\n",
                    "name": "stdout"
                },
                {
                    "output_type": "error",
                    "ename": "AllTrialsFailed",
                    "evalue": "",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAllTrialsFailed\u001b[0m                           Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-26-776b060ed9b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_trainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/operators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mtrained_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0mtrained_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_fit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainedIndividualOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schemas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/lib/lale/hyperopt.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Maximum alloted optimization time exceeded. Optimization exited prematurely'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;34m\"There are no evaluation tasks, cannot return argmin of task losses.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Only if there are some successful trail runs, return the best point in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"misc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# unpack the one-element lists to values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         ]\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAllTrialsFailed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAllTrialsFailed\u001b[0m: "
                    ]
                }
            ]
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "# tree_trained = tree_plan.auto_configure(train_x, train_y, optimizer= Hyperopt, cv=3, scoring='r2') ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**INTUITION:**\n    \nThe reason why we use PCA is because we want to reduce the dimensionality of the data.\n<br>Doing this allows us to compact the variance from the input data into as few dimensions as possible, Curse of Dimensionality.\n<br>We use a Tree Regressor because we want to understand the impact the independent variables have on the dependent variable. Also, the dependent variable is continuous and fit for a Regressor algorithm."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tree_trained.pretty_print(Ipython_display=True, show_imports=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tree_trained.visualize()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import sklearn.metrics\npredicted = tree_trained.predict(test_x)\n# print(f'R2 score {sklearn.metrics.r2_score(test_y, predicted):.2f}')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}