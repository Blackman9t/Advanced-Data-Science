{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6 with Spark",
      "language": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "pyspark_fundamentals.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "euMBbMirN2g2",
        "fRbptbgVN2g8",
        "B01LKvOiN2hL",
        "X37g8RBhN2hR",
        "6D9dM0-pN2hT",
        "U-YFF4-XN2hW",
        "9XjjCDVEN2hY",
        "M8p5Z0VmN2hd",
        "04WT3rsxN2hl",
        "fpi9zqkHN2hm",
        "SEe0r02cN2hs",
        "9DfxR-AUN2h5",
        "S-hY3D14N2iE",
        "xqZb1brTN2iI",
        "k4pWmFMoN2iS",
        "UaApsn6pN2iZ",
        "zsP7euLON2if",
        "YeKUFTyMN2im",
        "YTLSTmSUN2io",
        "Hf0FbJF9N2ip",
        "naVVvN_DN2ix",
        "Yv0goKrqN2i8",
        "yerPEcBGN2jF",
        "90YKQH5ON2jN",
        "-voYRwO_N2jW",
        "99F9NmP-N2ja",
        "1jPOwOnsN2js",
        "Er1tEAqeN2jt",
        "PcBSneZiN2ju"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blackman9t/Advanced-Data-Science/blob/master/pyspark_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxS3r19BN2gQ",
        "colab_type": "text"
      },
      "source": [
        "# IBM intro to spark lab, part 1 and DataCamp intro to Pyspark, lesson 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jitPgweFTVPZ",
        "colab_type": "text"
      },
      "source": [
        "**Spark is a fast and general cluster computing system for Big Data. It provides\n",
        "high-level APIs in Scala, Java, and Python, and an optimized engine that\n",
        "supports general computation graphs for data analysis. It also supports a\n",
        "rich set of higher-level tools including Spark SQL for SQL and structured\n",
        "data processing, MLlib for machine learning, GraphX for graph processing,\n",
        "and Spark Streaming for stream processing.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luauiGDyN2gS",
        "colab_type": "text"
      },
      "source": [
        "### IBM Table of Contents\n",
        "\n",
        "In the first four sections of this notebook, you'll learn about Spark with very simple examples. In the last two sections, you'll use what you learned to analyze data files that have more realistic data sets.\n",
        "\n",
        "Work with the SparkContext<br>\n",
        "1.1 Invoke the SparkContext<br>\n",
        "1.2 Check the Spark version<br>\n",
        "Work with RDDs<br>\n",
        "2.1 Create a collection<br>\n",
        "2.2 Create an RDD<br>\n",
        "2.3 View the data<br>\n",
        "2.4 Create another RDD<br>\n",
        "Manipulate data in RDDs<br>\n",
        "3.1 Update numeric values<br>\n",
        "3.2 Add numbers in an array<br>\n",
        "3.3 Split and count strings<br>\n",
        "3.4 Counts words with a pair RDD<br>\n",
        "Filter data<br>\n",
        "Analyze text data from a file<br>\n",
        "5.1 Get the data from a URL<br>\n",
        "5.2 Create an RDD from the file<br>\n",
        "5.3 Filter for a word<br>\n",
        "5.4 Count instances of a string at the beginning of words<br>\n",
        "5.5 Count instances of a string within words<br>\n",
        "Analyze numeric data from a file<br>\n",
        "Summary and next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ9dX-METRef",
        "colab_type": "text"
      },
      "source": [
        "Let's load our spark dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKZyuPLMTQRM",
        "colab_type": "code",
        "outputId": "bbac4262-a284-402d-aa30-9959b63389e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.4)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2aE24b6UKfF",
        "colab_type": "text"
      },
      "source": [
        "Now let's initialise a spark context if none exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL13kAMNURkd",
        "colab_type": "code",
        "outputId": "31f0947f-db3e-48a6-9f47-0dd6bf1aafba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "try:\n",
        "    conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
        "    sc = SparkContext(conf = conf)\n",
        "    print('SparkContext Initialised Successfully!')\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SparkContext Initialised Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Z3FDunUY-f",
        "colab_type": "code",
        "outputId": "91dc0682-4cf4-4ff3-9d55-ae603a4dac00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0cb7798dd2d8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>My App</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=My App>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxJk34X0UnxL",
        "colab_type": "text"
      },
      "source": [
        "Next, let's create our Spark session wherein we will perform parallelized activities through the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLF95O3DUpST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('My App').getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8yDmNtkVNRR",
        "colab_type": "code",
        "outputId": "6a110bd4-8b95-424d-f52f-222bed834320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "spark"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0cb7798dd2d8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>My App</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f04e6dd4240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSwVTJqAN2gT",
        "colab_type": "text"
      },
      "source": [
        "To acquire and extract the data, simply run the following Bash scripts: Dataset acquired from GroupLens. Lets download the dataset. To download the data, we will use !wget to download it from IBM Object Storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "PYLDNvuXN2gU",
        "colab_type": "code",
        "outputId": "91a43f86-d28f-405f-cc4e-386fd2d90a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!wget -O moviedataset.zip https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/moviedataset.zip\n",
        "print('unziping ...')\n",
        "!unzip -o -j moviedataset.zip "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 19:29:31--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/moviedataset.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160301210 (153M) [application/zip]\n",
            "Saving to: ‘moviedataset.zip’\n",
            "\n",
            "moviedataset.zip    100%[===================>] 152.88M  35.4MB/s    in 5.0s    \n",
            "\n",
            "2020-01-31 19:29:37 (30.4 MB/s) - ‘moviedataset.zip’ saved [160301210/160301210]\n",
            "\n",
            "unziping ...\n",
            "Archive:  moviedataset.zip\n",
            "  inflating: links.csv               \n",
            "  inflating: movies.csv              \n",
            "  inflating: ratings.csv             \n",
            "  inflating: README.txt              \n",
            "  inflating: tags.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKrW2rs7N2gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings_data = 'ratings.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPd7lrKnN2ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29785e31-e2cd-41d8-b495-d16479931b15"
      },
      "source": [
        "import pandas as pd\n",
        "ratings_df = pd.read_csv(ratings_data)\n",
        "ratings_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22884377, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmGlRKtPN2gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "fef7da70-6470-4460-b302-7d37505f655d"
      },
      "source": [
        "ratings_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>169</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1204927694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2471</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1204927438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>48516</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1204927435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2571</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1436165433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>109487</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1436165496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1      169     2.5  1204927694\n",
              "1       1     2471     3.0  1204927438\n",
              "2       1    48516     5.0  1204927435\n",
              "3       2     2571     3.5  1436165433\n",
              "4       2   109487     4.0  1436165496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXs0vXZeN2gf",
        "colab_type": "text"
      },
      "source": [
        "To save the ratings dataframe as a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CewYP7zAN2gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rating_csv = ratings_df.to_csv() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM8yUdk2N2gi",
        "colab_type": "text"
      },
      "source": [
        "The SparkSession class has a method to save a Pandas DataFrame as a Spark DataFrame.\n",
        "\n",
        "The .createDataFrame() method takes a pandas DataFrame and returns a Spark DataFrame.\n",
        "\n",
        "The output of this method is stored locally, not in the SparkSession catalog. This means that you can use all the Spark DataFrame methods on it, but you can't access the data in other contexts.\n",
        "\n",
        "For example, a SQL query (using the .sql() method) that references your DataFrame will throw an error. To access the data in this way, you have to save it as a temporary table.\n",
        "\n",
        "You can do this using the .createTempView() Spark DataFrame method, which takes as its only argument the name of the temporary table you'd like to register. This method registers the DataFrame as a table in the catalog, but as this table is temporary, it can only be accessed from the specific SparkSession used to create the Spark DataFrame.\n",
        "\n",
        "There is also the method .createOrReplaceTempView(). This safely creates a new temporary table if nothing was there before, or updates an existing table if one was already defined. You'll use this method to avoid running into problems with duplicate tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUbJ-c5N2gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3de27d09-52b3-478f-9583-0b1d978e71ad"
      },
      "source": [
        "spark.catalog.listTables()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5OxHWv1N2gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "2894d244-4e23-4e20-f0a5-c9fc4f7f3ba9"
      },
      "source": [
        "movies_df = pd.read_csv('movies.csv')\n",
        "print('movies_df shape is {}'.format(movies_df.shape))\n",
        "movies_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movies_df shape is (34208, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  ...                                       genres\n",
              "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1        2  ...                   Adventure|Children|Fantasy\n",
              "2        3  ...                               Comedy|Romance\n",
              "3        4  ...                         Comedy|Drama|Romance\n",
              "4        5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5C7MYoN2gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "2e0e915f-0c2e-4c32-81f8-df2ac58197bf"
      },
      "source": [
        "# Let's make movies_df a Spark DataFrame\n",
        "\n",
        "spark_movies_df = spark.createDataFrame(movies_df)\n",
        "spark_movies_df.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
            "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
            "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
            "|      9| Sudden Death (1995)|              Action|\n",
            "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
            "|     11|American Presiden...|Comedy|Drama|Romance|\n",
            "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
            "|     13|        Balto (1995)|Adventure|Animati...|\n",
            "|     14|        Nixon (1995)|               Drama|\n",
            "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
            "|     16|       Casino (1995)|         Crime|Drama|\n",
            "|     17|Sense and Sensibi...|       Drama|Romance|\n",
            "|     18|   Four Rooms (1995)|              Comedy|\n",
            "|     19|Ace Ventura: When...|              Comedy|\n",
            "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4x9x2dvN2gs",
        "colab_type": "text"
      },
      "source": [
        "Let's print the schema of the above spark DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoUdoy0vN2gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5d4aded5-9449-4ef5-e538-af0cbc65d56a"
      },
      "source": [
        "print(spark_movies_df.printSchema())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- movieId: long (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skF0glj7N-PS",
        "colab_type": "text"
      },
      "source": [
        "### cardinality in Databases\n",
        "\n",
        "In the context of databases, cardinality refers to the uniqueness of data values contained in a column. High cardinality means that the column contains a large percentage of totally unique values. Low cardinality means that the column contains a lot of “repeats” in its data range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Exn6AJTN2gv",
        "colab_type": "text"
      },
      "source": [
        "Now let's add the spark dataframe we just created from the movies_df as a temporary file with name 'temp_movies', to our spark session catalog.\n",
        "<br>We use the .createOrReplace() method to avoid duplicates, just incase a table of same name exists.<br>\n",
        "If such a table exists then the .replaceOrCreate() method will update the table and not duplicate it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqbcp8iEN2gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark_movies_df.createOrReplaceTempView(\"temp_movies\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXPnSpZ9N2gy",
        "colab_type": "text"
      },
      "source": [
        "Let's print out the tables in our catalog again to see if the temp_movies is included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcqBFdw1N2gz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bcf8416-04b0-4206-e94d-5573483b5aab"
      },
      "source": [
        "print(spark.catalog.listTables())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tmuWwZrN2g1",
        "colab_type": "text"
      },
      "source": [
        "We can clearly see the temp_movies table we added. \n",
        "<br>Know that this table will only be available in this spark session as a temporary table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euMBbMirN2g2",
        "colab_type": "text"
      },
      "source": [
        "### Dropping the middle man\n",
        "Now you know how to put data into Spark via pandas, but you're probably wondering why deal with pandas at all? Wouldn't it be easier to just read a text file straight into Spark? Of course it would!\n",
        "\n",
        "Luckily, your SparkSession has a .read attribute which has several methods for reading different data sources into Spark DataFrames. Using these you can create a DataFrame from a .csv file just like with regular pandas DataFrames!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_GYZWyRN2g3",
        "colab_type": "text"
      },
      "source": [
        "Use the .read.csv() method to create a Spark DataFrame called spark_links for the links.csv file above.\n",
        "<br>Pass the argument header=True so that Spark knows to take the column names from the first line of the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzteHX60N2g3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark_links_df = spark.read.csv('links.csv', header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArSHtQYjN2g5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "44b96da8-e445-4c30-b331-8c6a84dd000c"
      },
      "source": [
        "# let's see the first 20 rows of the spark_links_df \n",
        "spark_links_df.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|movieId| imdbId|tmdbId|\n",
            "+-------+-------+------+\n",
            "|      1|0114709|   862|\n",
            "|      2|0113497|  8844|\n",
            "|      3|0113228| 15602|\n",
            "|      4|0114885| 31357|\n",
            "|      5|0113041| 11862|\n",
            "|      6|0113277|   949|\n",
            "|      7|0114319| 11860|\n",
            "|      8|0112302| 45325|\n",
            "|      9|0114576|  9091|\n",
            "|     10|0113189|   710|\n",
            "|     11|0112346|  9087|\n",
            "|     12|0112896| 12110|\n",
            "|     13|0112453| 21032|\n",
            "|     14|0113987| 10858|\n",
            "|     15|0112760|  1408|\n",
            "|     16|0112641|   524|\n",
            "|     17|0114388|  4584|\n",
            "|     18|0113101|     5|\n",
            "|     19|0112281|  9273|\n",
            "|     20|0113845| 11517|\n",
            "+-------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXx5AOQ2N2g7",
        "colab_type": "text"
      },
      "source": [
        "## 1. Work with the SparkContext object\n",
        "The Spark driver application uses the SparkContext object to allow a programming interface to interact with the driver application. The SparkContext object tells Spark how and where to access a cluster.\n",
        "\n",
        "The Watson Studio notebook environment predefines the Spark context for you.\n",
        "\n",
        "In other environments, you need to pick an interpreter (for example, pyspark for Python) and create a SparkConf object to initialize a SparkContext object. For example:<br>\n",
        "```\n",
        "from pyspark import SparkContext, SparkConf\n",
        "conf = SparkConf().setAppName(appName).setMaster(master)\n",
        "sc = SparkContext(conf=conf)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRbptbgVN2g8",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Invoke the SparkContext\n",
        "Run the following cell to invoke the SparkContext:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8EBK__kN2g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "36ee56b9-b676-47d2-ed60-3ca7345195ef"
      },
      "source": [
        "sc"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0cb7798dd2d8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>My App</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=My App>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI9n8DrgN2g_",
        "colab_type": "text"
      },
      "source": [
        "Let's check if there is an existing spark session that we can use.<br>Otherwise we use the .getOrCreate() method to make one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXF9adrnN2g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUnV0e62N2hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create my_spark session either from existion or a new one\n",
        "try:\n",
        "    my_spark = SparkSession.builder.getOrCreate()\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjxDQVxiN2hG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9805d83-0d1d-42e5-e22a-4bd629c1b0e0"
      },
      "source": [
        "# Print my_spark\n",
        "print(my_spark)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7f04e6dd4240>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX92Q99UN2hI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e14a99b-c256-427d-f33d-560b47aeea58"
      },
      "source": [
        "my_spark.catalog.listTables()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hXjYstGN2hK",
        "colab_type": "text"
      },
      "source": [
        "my_spark SparkSession also accesses the current session database as expected. In addition to spark session pre-defined for us by IBM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B01LKvOiN2hL",
        "colab_type": "text"
      },
      "source": [
        "### Viewing tables\n",
        "Once you've created a SparkSession, you can start poking around to see what data is in your cluster!\n",
        "\n",
        "Your SparkSession has an attribute called catalog which lists all the data inside the cluster. This attribute has a few methods for extracting different pieces of information.\n",
        "\n",
        "One of the most useful is the .listTables() method, which returns the names of all the tables in your cluster as a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BUwIAPrN2hM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81827d86-31f6-48c7-8525-5eee906333ff"
      },
      "source": [
        "# See what tables are in your cluster by calling spark.catalog.listTables() and printing the result!\n",
        "try:\n",
        "    print(spark.catalog.listTables())\n",
        "except Exception as e:\n",
        "    print(type(e),e)  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X37g8RBhN2hR",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Check the Spark version\n",
        "Check the version of the Spark driver application:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7sYYXJUVN2hR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e890b17-332a-4e0b-e0fa-3413c4e0c67a"
      },
      "source": [
        "sc.version"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFb-U92gN2hT",
        "colab_type": "text"
      },
      "source": [
        "## 2. Work with Resilient Distributed Datasets\n",
        "Spark uses an abstraction for working with data called a Resilient Distributed Dataset (RDD). An RDD is a collection of elements that can be operated on in parallel. RDDs are immutable, so you can't update the data in them. To update data in an RDD, you must create a new RDD. In Spark, all work is done by creating new RDDs, transforming existing RDDs, or using RDDs to compute results. When working with RDDs, the Spark driver application automatically distributes the work across the cluster.\n",
        "\n",
        "You can construct RDDs by parallelizing existing Python collections (lists), by manipulating RDDs, or by manipulating files in HDFS or any other storage system.\n",
        "\n",
        "You can run these types of methods on RDDs:\n",
        "\n",
        "Actions: query the data and return values\n",
        "Transformations: manipulate data values and return pointers to new RDDs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D9dM0-pN2hT",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Create a collection\n",
        "Create a Python collection of the numbers 1 - 10:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb6pETNEN2hU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed78f50f-0443-48c6-ab20-5f7f64eccf24"
      },
      "source": [
        "x = list(range(1, 11))\n",
        "print(x)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-YFF4-XN2hW",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Create an RDD\n",
        "Put the collection into an RDD named x_nbr_rdd using the parallelize method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtrcM7dLN2hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_nbr_rdd = sc.parallelize(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XjjCDVEN2hY",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 View the data\n",
        "View the first element in the RDD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHaDTRCyN2hZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d2bfbff-14af-48b1-b2ac-d3026aff1b85"
      },
      "source": [
        "x_nbr_rdd.first()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p0bRwr9N2hb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f356d20a-6af7-4944-ea14-b1af12f0d279"
      },
      "source": [
        "# Let's view the first five items\n",
        "x_nbr_rdd.take(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8p5Z0VmN2hd",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 Create another RDD\n",
        "Create a Python collection that contains strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2KNwB_lN2he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = [\"Hello Human\", \"My name is Spark\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q32LWrBDN2hf",
        "colab_type": "text"
      },
      "source": [
        "Put the collection into an RDD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXWNadvYN2hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_str_rdd = sc.parallelize(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZhcbgyN2hh",
        "colab_type": "text"
      },
      "source": [
        "View the first element in the RDD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF-L_5QZN2hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed099e41-fff9-43b6-a976-e893b75ff16f"
      },
      "source": [
        "y_str_rdd.first()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Human'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsI3ncLaN2hk",
        "colab_type": "text"
      },
      "source": [
        "You created the string \"Hello Human\" and you returned it as the first element of the RDD. To analyze a set of words, you can map each word into an RDD element."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7dBuj9iN2hl",
        "colab_type": "text"
      },
      "source": [
        "## 3. Manipulate data in RDDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04WT3rsxN2hl",
        "colab_type": "text"
      },
      "source": [
        "### 3. Manipulate data in RDDs\n",
        "Remember that to manipulate data, you use transformation functions.<br>\n",
        "\n",
        "Here are some common Python transformation functions that you'll be using in this notebook:<br>\n",
        "\n",
        "map(func): returns a new RDD with the results of running the specified function on each element<br>\n",
        "filter(func): returns a new RDD with the elements for which the specified function returns true<br>\n",
        "distinct([numTasks])): returns a new RDD that contains the distinct elements of the source RDD<br>\n",
        "flatMap(func): returns a new RDD by first running the specified function on all elements, returning 0 or more results for each original element, and then flattening the results into individual elements<br>\n",
        "You can also create functions that run a single expression and don't have a name with the Python lambda keyword. <br>For example, this function returns the sum of its arguments: lambda a , b : a + b."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpi9zqkHN2hm",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Update numeric values\n",
        "Run the map() function with the lambda keyword to replace each element, X, in your first RDD (the one that has numeric values) with X+1. Because RDDs are immutable, you need to specify a new RDD name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COX3nTAaN2hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_nbr_rdd2 = x_nbr_rdd.map(lambda x: x + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8mVn63TN2ho",
        "colab_type": "text"
      },
      "source": [
        "Now look at the elements of the new RDD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGw45aVkN2ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1c4a38a-943c-4b19-a8a0-e712d32aba06"
      },
      "source": [
        "x_nbr_rdd2.collect()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ4dhGm3N2hq",
        "colab_type": "text"
      },
      "source": [
        "Be careful with the collect method! It returns all elements of the RDD to the driver. Returning a large data set might not be very useful. <br>No-one wants to scroll through a million rows!... Use rdd.take(n) instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2i0qfvmN2hr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2b0e531-c3c1-479e-8479-0526f9f08e96"
      },
      "source": [
        "# To find the len or number of elements in a collection\n",
        "len(x_nbr_rdd2.collect())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEe0r02cN2hs",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Add numbers in an array\n",
        "An array of values is a common data format where multiple values are contained in one element. You can manipulate the individual values if you split them up into separate elements.\n",
        "\n",
        "Create an array of numbers by including quotation marks around the whole set of numbers. If you omit the quotation marks, you get a collection of numbers instead of an array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mNqAeRaN2ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = ['1, 2, 3, 4, 5, 6, 7, 8, 9, 10']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVA8yRxHN2hv",
        "colab_type": "text"
      },
      "source": [
        "Create an RDD for the array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x_YYSEFN2hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_rd = sc.parallelize(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dGERXiAN2h0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f78fe01-62c4-45cc-eb53-db5206269630"
      },
      "source": [
        "y_rd.take(1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1, 2, 3, 4, 5, 6, 7, 8, 9, 10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCjnERO7N2h2",
        "colab_type": "text"
      },
      "source": [
        "Split the values at commas and add values in the positions 2 and 9 in the array. <br>Keep in mind that an array starts with position 0. Use a backslash character, , to break the line of code for clarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53OVHA4yN2h2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_rd = y_rd.map(lambda y: y.split(',')).\\\n",
        "                 map(lambda y: int(y[2]) + int(y[9]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "yvaIVO-qN2h3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "254c377b-eb50-4eb9-efe9-490703f2a9f8"
      },
      "source": [
        "sum_rd.first()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DfxR-AUN2h5",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Split and count text strings\n",
        "Create an RDD with a text string and show the first element:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXQb66-9N2h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Words = [\"Hello Human. I'm Spark and I love running analysis on data.\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbKRwrGoN2h9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ddd359d-f2eb-42d5-a3e9-3981122f8a93"
      },
      "source": [
        "words_rd = sc.parallelize(Words)\n",
        "words_rd.first()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello Human. I'm Spark and I love running analysis on data.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYYn23uwN2h-",
        "colab_type": "text"
      },
      "source": [
        "Split the string into separate lines at the space characters and look at the first element:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0zlA-PlN2h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Words_rd2 = words_rd.map(lambda x: x.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REdC_LcMN2iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5eedd220-a8bf-4165-c60c-1b95c5fb9cd0"
      },
      "source": [
        "Words_rd2.first()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Human.',\n",
              " \"I'm\",\n",
              " 'Spark',\n",
              " 'and',\n",
              " 'I',\n",
              " 'love',\n",
              " 'running',\n",
              " 'analysis',\n",
              " 'on',\n",
              " 'data.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Dlst_TN2iB",
        "colab_type": "text"
      },
      "source": [
        "Count the number of elements in this RDD with the count() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiOvt2R8N2iB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2bb49cd-efb8-41e6-a26b-fad220c1bf98"
      },
      "source": [
        "Words_rd2.count()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EdBusPsN2iD",
        "colab_type": "text"
      },
      "source": [
        "Of course, you already knew that there was only one element because you ran the first() method and it returned the whole string. <br>Splitting the string into multiple lines did not create multiple elements.\n",
        "\n",
        "Now split the string again, but this time with the flatmap() method, and look at the first three elements:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-hY3D14N2iE",
        "colab_type": "text"
      },
      "source": [
        "### Splitting string with flatmap() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URRo-e6IN2iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Words_rd2 = words_rd.flatMap(lambda line: line.split(\" \"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDgCxjt5N2iG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71eac775-9dc4-4dac-bd98-d25392906cef"
      },
      "source": [
        "# Let's see the first three elements now\n",
        "Words_rd2.take(3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'Human.', \"I'm\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH-cfGgyN2iI",
        "colab_type": "text"
      },
      "source": [
        "This time each word is separated into its own element."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqZb1brTN2iI",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Count words with a pair RDD\n",
        "A common way to count the number of instances of words in an RDD is to create a pair RDD. <br>A pair RDD converts each word into a key-value pair: the word is the key and the number 1 is the value. <br>Because the values are all 1, when you add the values for a particular word, you get the number of instances of that word.\n",
        "\n",
        "Create an RDD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWVyJi5BN2iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebfafa57-b8f6-4fda-fb74-ca8e1a62ed08"
      },
      "source": [
        "z = [\"First,Line\", \"Second,Line\", \"and,Third,Line\"]\n",
        "z_str_rdd = sc.parallelize(z)\n",
        "z_str_rdd.first()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First,Line'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaEVbghXN2iK",
        "colab_type": "text"
      },
      "source": [
        "Split the elements into individual words with the flatmap() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyJ3mb5dN2iK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84e194c8-0a26-44c8-d339-770363db54d6"
      },
      "source": [
        "z_str_rdd_split_flatmap = z_str_rdd.flatMap(lambda x: x.split(','))\n",
        "z_str_rdd_split_flatmap.first()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsyv4-_hN2iL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66f0c4ce-7b2f-464a-ac9e-a41e15b1530f"
      },
      "source": [
        "# Let's see all the words\n",
        "z_str_rdd_split_flatmap.collect()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First', 'Line', 'Second', 'Line', 'and', 'Third', 'Line']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8tKcmUHN2iN",
        "colab_type": "text"
      },
      "source": [
        "Convert the elements into key-value pairs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ELNd5HIN2iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29c4e442-8d65-4bcf-ff17-dcfadef145f3"
      },
      "source": [
        "countWords = z_str_rdd_split_flatmap.map(lambda x: (x, 1))\n",
        "countWords.take(3)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('First', 1), ('Line', 1), ('Second', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGUBJhYGN2iQ",
        "colab_type": "text"
      },
      "source": [
        "Now sum all the values by key to find the number of instances for each word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78h7nf-sN2iR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa2eb663-a140-4c5d-f722-a98ee5ca3e4d"
      },
      "source": [
        "from operator import add\n",
        "countwords2 = countWords.reduceByKey(add)\n",
        "countwords2.collect()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('First', 1), ('Line', 3), ('Second', 1), ('and', 1), ('Third', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4pWmFMoN2iS",
        "colab_type": "text"
      },
      "source": [
        "### 4. Filter data\n",
        "The filter command creates a new RDD from another RDD based on a filter criteria. The filter syntax is:\n",
        "\n",
        ".filter(lambda line: \"Filter Criteria Value\" in line)\n",
        "\n",
        "Hint: Use a simple python print command to add a string to your Spark results and to run multiple actions in single cell.\n",
        "\n",
        "Find the number of instances of the word Line in the z_str_rdd_split_flatmap RDD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6vP7EdRN2iS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6aa67c5-ba01-4d13-f5b9-6731d2c211a9"
      },
      "source": [
        "words_rd3 = z_str_rdd_split_flatmap.filter(lambda x: 'Line' in x)\n",
        "print(\"The count of word \" + str(words_rd3.first()))\n",
        "print(\"is \" + str(words_rd3.count()))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The count of word Line\n",
            "is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaApsn6pN2iZ",
        "colab_type": "text"
      },
      "source": [
        "### 5. Analyze text data from a file\n",
        "In this section, you'll download a file from a URL, create an RDD from it, and analyze the text in it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISdN5ay-N2ia",
        "colab_type": "text"
      },
      "source": [
        "You can run shell commands by prefacing them with an exclamation point (!).\n",
        "<br>Remove any files with the same name as the file that you're going to download and then load a file named README.md from a URL into the filesystem for Spark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-R_DNreN2ia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a8309034-0c31-4b02-f550-4158454eb68a"
      },
      "source": [
        "!rm README.md* -f\n",
        "!wget https://raw.githubusercontent.com/carloapp2/SparkPOT/master/README.md"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 19:30:07--  https://raw.githubusercontent.com/carloapp2/SparkPOT/master/README.md\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3624 (3.5K) [text/plain]\n",
            "Saving to: ‘README.md’\n",
            "\n",
            "\rREADME.md             0%[                    ]       0  --.-KB/s               \rREADME.md           100%[===================>]   3.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-31 19:30:07 (112 MB/s) - ‘README.md’ saved [3624/3624]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktB5M5DvN2ib",
        "colab_type": "text"
      },
      "source": [
        "5.2 Create an RDD from the file\n",
        "Use the textFile method to create an RDD named textfile_rdd based on the README.md file. <br>The RDD will contain one element for each line in the README.md file. Also, count the number of lines in the RDD, which is the same as the number of lines in the text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2io0xqLbN2ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a83925f7-43b5-492a-d212-7843b037c9ee"
      },
      "source": [
        "# Now let's read the READme.md text file to an RDD\n",
        "textfile_rdd = sc.textFile('README.md')\n",
        "# Now lets see the number of lines in the file\n",
        "textfile_rdd.count()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfsfeLrfS4dF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f7e8ad74-a03e-4256-8696-f3cb551336fb"
      },
      "source": [
        "# let's see the first 5 lines\n",
        "textfile_rdd.take(5)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# Apache Spark',\n",
              " '',\n",
              " 'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
              " 'high-level APIs in Scala, Java, and Python, and an optimized engine that',\n",
              " 'supports general computation graphs for data analysis. It also supports a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsP7euLON2if",
        "colab_type": "text"
      },
      "source": [
        "### 5.3 Filter for a word\n",
        "Filter the RDD to keep only the elements that contain the word \"Spark\" with the filter transformation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaADQbJ3N2ii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9d707713-2fdd-46e6-eef0-dbda75a14a23"
      },
      "source": [
        "spark_lines = textfile_rdd.filter(lambda x: \"Spark\" in x)\n",
        "# Let's see the first 10 lines from our filter\n",
        "spark_lines.take(10)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# Apache Spark',\n",
              " 'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
              " 'rich set of higher-level tools including Spark SQL for SQL and structured',\n",
              " 'and Spark Streaming for stream processing.',\n",
              " 'You can find the latest Spark documentation, including a programming',\n",
              " '## Building Spark',\n",
              " 'Spark is built using [Apache Maven](http://maven.apache.org/).',\n",
              " 'To build Spark and its example programs, run:',\n",
              " '[\"Building Spark\"](http://spark.apache.org/docs/latest/building-spark.html).',\n",
              " 'The easiest way to start using Spark is through the Scala shell:']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp654g06N2ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5937648c-584a-40e8-892b-3055943be449"
      },
      "source": [
        "# Let's also see howmany lines in total have \"Spark\" in them\n",
        "spark_lines.count()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeKUFTyMN2im",
        "colab_type": "text"
      },
      "source": [
        "### 5.4 Count the instances of a string at the beginning of words\n",
        "Count the number of times the substring \"Spark\" appears at the beginning of a word in the original text.\n",
        "\n",
        "Here's what you need to do:\n",
        "\n",
        "Run a flatMap transformation on the Spark_lines RDD and split on white spaces.<br>\n",
        "Create an RDD with key-value pairs where the first element of the tuple is the word and the second element is the number 1.<br>\n",
        "Run a reduceByKey method with the add function to count the number of instances of each word.<br>\n",
        "Filter the resulting RDD to keep only the elements that start with the word \"Spark\". <br>In Python, the syntax to determine whether a string starts with a token is: string.startswith(\"token\")<br>\n",
        "Display the resulting list of elements that start with \"Spark\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehg7CB36N2im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e28792a5-71b9-408c-eb03-ad2e8e57efb0"
      },
      "source": [
        "# Let's get to it.\n",
        "temp = textfile_rdd.flatMap(lambda x: x.split(\" \")).map(lambda x: (x,1)).reduceByKey(add)\n",
        "temp.take(10)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('#', 1),\n",
              " ('Apache', 1),\n",
              " ('Spark', 14),\n",
              " ('', 75),\n",
              " ('is', 6),\n",
              " ('a', 9),\n",
              " ('fast', 1),\n",
              " ('and', 10),\n",
              " ('general', 2),\n",
              " ('cluster', 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjN-saLzUZNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "0b91166a-8546-43b5-8e5e-94ea792f7669"
      },
      "source": [
        "# Now let's filter by Spark\n",
        "temp.filter(lambda x: x[0].startswith(\"Spark\")).collect()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Spark', 14),\n",
              " ('Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
              " ('SparkPi', 2),\n",
              " ('Spark](#building-spark).', 1),\n",
              " ('Spark.', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTLSTmSUN2io",
        "colab_type": "text"
      },
      "source": [
        "### 5.5 Count instances of a string within words\n",
        "Now filter and display the elements that contain the substring \"Spark\" anywhere in the word, instead of just at the beginning of words like the last section. <br>Your result should be a superset of the previous result.\n",
        "\n",
        "The Python syntax to determine whether a string contains a particular token is: \"token\" in string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jc56jWON2io",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b4e4796c-93b6-49f9-e0a5-892f4c6c9f44"
      },
      "source": [
        "temp.filter(lambda x: \"Spark\" in x[0]).collect()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Spark', 14),\n",
              " ('Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
              " ('SparkPi', 2),\n",
              " ('Spark](#building-spark).', 1),\n",
              " ('tests](https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-AutomatedTesting).',\n",
              "  1),\n",
              " ('Spark.', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf0FbJF9N2ip",
        "colab_type": "text"
      },
      "source": [
        "### 6. Analyze numeric data from a file\n",
        "You'll analyze a sample file that contains instructor names and scores. <br>The file has the following format: Instructor Name,Score1,Score2,Score3,Score4. Here is an example line from the text file: \"Carlo,5,3,3,4\"\n",
        "\n",
        "Add all scores and report on results:\n",
        "\n",
        "Download the file.<br>\n",
        "Load the text file into an RDD.<br>\n",
        "Run a transformation to create an RDD with the instructor names and the sum of the 4 scores per instructor.<br>\n",
        "Run a second transformation to compute the average score for each instructor.<br>\n",
        "Display the first 5 results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbh-a4FuN2iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8246218b-1194-451c-91b1-1b551dd166a5"
      },
      "source": [
        "# downloading the file\n",
        "!rm Scores.txt* -f\n",
        "!wget https://raw.githubusercontent.com/carloapp2/SparkPOT/master/Scores.txt"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 19:30:17--  https://raw.githubusercontent.com/carloapp2/SparkPOT/master/Scores.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75 [text/plain]\n",
            "Saving to: ‘Scores.txt’\n",
            "\n",
            "\rScores.txt            0%[                    ]       0  --.-KB/s               \rScores.txt          100%[===================>]      75  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-31 19:30:17 (17.3 MB/s) - ‘Scores.txt’ saved [75/75]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YN-2zUbN2ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "ff27b024-22fa-412a-f17b-3d690d5ac60c"
      },
      "source": [
        "raw_rdd = sc.textFile('Scores.txt')\n",
        "# Let's see first 5 elements\n",
        "raw_rdd.take(5)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Carlo,5,3,3,4',\n",
              " 'Mokhtar,2,5,5,3',\n",
              " 'Jacques,4,2,4,5',\n",
              " 'Braden,5,3,2,5',\n",
              " 'Chris,5,4,5,1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM7QijSaN2is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "84747715-2bed-4a28-fd8f-3eacfe037a94"
      },
      "source": [
        "sum_scores = raw_rdd.map(lambda x: x.split(\",\")).map(lambda y: (y[0], int(y[1])+int(y[2])+int(y[3])+int(y[4])))\n",
        "sum_scores.take(5)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Carlo', 15),\n",
              " ('Mokhtar', 15),\n",
              " ('Jacques', 15),\n",
              " ('Braden', 15),\n",
              " ('Chris', 15)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJF3gVYSN2iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = sum_scores.map(lambda y: (y[0], y[1], y[1]/4.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYz00SFJN2iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9eb820e0-132a-4694-bde5-42a33ab834ab"
      },
      "source": [
        "final.take(5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Carlo', 15, 3.75),\n",
              " ('Mokhtar', 15, 3.75),\n",
              " ('Jacques', 15, 3.75),\n",
              " ('Braden', 15, 3.75),\n",
              " ('Chris', 15, 3.75)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhegwnUrN2ix",
        "colab_type": "text"
      },
      "source": [
        "# IBM intro to spark lab, part 2 and DataCamp intro to Pyspark, lesson 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naVVvN_DN2ix",
        "colab_type": "text"
      },
      "source": [
        "### DataCamp Lesson 2:\n",
        "\n",
        "Creating Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fl1XmJBN2iy",
        "colab_type": "text"
      },
      "source": [
        "Let's look at performing column-wise operations. \n",
        "<br>In Spark you can do this using the .withColumn() method, which takes two arguments. First, a string with the name of your new column, and second the new column itself.\n",
        "<br>The new column must be an object of class Column. Creating one of these is as easy as extracting a column from your DataFrame using df.colName.\n",
        "\n",
        "Updating a Spark DataFrame is somewhat different than working in pandas because the Spark DataFrame is immutable. <br>This means that it can't be changed, and so columns can't be updated in place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qfig_n8pN2iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "66d91fde-418f-43ab-91ec-7e1820bea687"
      },
      "source": [
        "# let's create a new spark dataframe from the tags.csv file\n",
        "spark_tags_df = spark.read.csv('tags.csv', header=True)\n",
        "spark_tags_df.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+--------------------+----------+\n",
            "|userId|movieId|                 tag| timestamp|\n",
            "+------+-------+--------------------+----------+\n",
            "|    19|   2324|         bittersweet|1428651158|\n",
            "|    19|   2324|           holocaust|1428651112|\n",
            "|    19|   2324|        World War II|1428651118|\n",
            "|    23|   7075|           hilarious|1378675786|\n",
            "|    23|   7075|          Underrated|1378675786|\n",
            "|    54|    357|              Garath|1354417040|\n",
            "|    57|    260|     Science Fiction|1433167996|\n",
            "|   120| 109374|      cinematography|1445114894|\n",
            "|   157|   7142|          bad script|1362371627|\n",
            "|   157|   7142|             no plot|1362371612|\n",
            "|   157|  52975|           feel good|1362371683|\n",
            "|   157|  52975|         great music|1362371698|\n",
            "|   157|  52975|             musical|1362371718|\n",
            "|   157|  55267|        large family|1362371415|\n",
            "|   157|  55267|           realistic|1362371439|\n",
            "|   157|  55267|            romantic|1362371491|\n",
            "|   157|  55267|        Steve Carell|1362371472|\n",
            "|   157|  55267|           the music|1362371394|\n",
            "|   157|  55872|           builds up|1362371915|\n",
            "|   157|  55872|different but ver...|1362371939|\n",
            "+------+-------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33dJBpqBN2i1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's add this table to our spark session catalog\n",
        "spark_tags_df.createOrReplaceTempView(\"spark_tags_df\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThhGn6ztN2i5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b1e2e86-d7be-457f-90d0-5e173fd17fb7"
      },
      "source": [
        "print('spark_tags_df has {} rows and {} columns.'.format(spark_tags_df.count(), len(spark_tags_df.columns)))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark_tags_df has 586994 rows and 4 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd37nrUxN2i6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "68463915-2fb9-4707-fdbd-bd8f7744f597"
      },
      "source": [
        "# Now let's see the tables in our spark session catalog\n",
        "spark.catalog.listTables()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='spark_tags_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv0goKrqN2i8",
        "colab_type": "text"
      },
      "source": [
        "### Creating a new copy of an existing spark dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lOlQ9EaN2i9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "cad275d6-1145-4ae6-b543-4cd9fc13aed3"
      },
      "source": [
        "# We use the spark.table() function to create a new table from an existing one\n",
        "# This function takes the name of the existing table as a string\n",
        "new_spark_tags_df = spark.table(\"spark_tags_df\")\n",
        "new_spark_tags_df.show(10)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+---------------+----------+\n",
            "|userId|movieId|            tag| timestamp|\n",
            "+------+-------+---------------+----------+\n",
            "|    19|   2324|    bittersweet|1428651158|\n",
            "|    19|   2324|      holocaust|1428651112|\n",
            "|    19|   2324|   World War II|1428651118|\n",
            "|    23|   7075|      hilarious|1378675786|\n",
            "|    23|   7075|     Underrated|1378675786|\n",
            "|    54|    357|         Garath|1354417040|\n",
            "|    57|    260|Science Fiction|1433167996|\n",
            "|   120| 109374| cinematography|1445114894|\n",
            "|   157|   7142|     bad script|1362371627|\n",
            "|   157|   7142|        no plot|1362371612|\n",
            "+------+-------+---------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiUV1VQzN2i-",
        "colab_type": "text"
      },
      "source": [
        "Now, let's add an extra column to new_spark_tags_df by just adding 1 to the userId values.<br>\n",
        "As usual, this means we are basically creating a new data frame, since data frames are immutable in spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "KJHvLCHTN2i_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0c798eb5-444a-4f2c-f0b6-9d23c214d106"
      },
      "source": [
        "new_spark_tags_df = new_spark_tags_df.withColumn('extra', new_spark_tags_df.userId+1)\n",
        "new_spark_tags_df.show(5)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------------+----------+-----+\n",
            "|userId|movieId|         tag| timestamp|extra|\n",
            "+------+-------+------------+----------+-----+\n",
            "|    19|   2324| bittersweet|1428651158| 20.0|\n",
            "|    19|   2324|   holocaust|1428651112| 20.0|\n",
            "|    19|   2324|World War II|1428651118| 20.0|\n",
            "|    23|   7075|   hilarious|1378675786| 24.0|\n",
            "|    23|   7075|  Underrated|1378675786| 24.0|\n",
            "+------+-------+------------+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2_eICu7N2jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's add the spark_links_df to our catalog. \n",
        "# This is the spark movie links data frame\n",
        "spark_links_df.createOrReplaceTempView('spark_links_df')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_dG6tizZN2jB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7b7cc0cb-edb0-4726-9577-2da3c930146d"
      },
      "source": [
        "spark.catalog.listTables()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='spark_links_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='spark_tags_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2w1ZwP1MN2jC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5bf7d4bc-e3fc-42c3-8c62-82bd1eb8bc24"
      },
      "source": [
        "spark_links_df.show(5)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|movieId| imdbId|tmdbId|\n",
            "+-------+-------+------+\n",
            "|      1|0114709|   862|\n",
            "|      2|0113497|  8844|\n",
            "|      3|0113228| 15602|\n",
            "|      4|0114885| 31357|\n",
            "|      5|0113041| 11862|\n",
            "+-------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYp4Le0CN2jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "380bbcb1-9dd3-41cc-c442-7c53e8f39c7b"
      },
      "source": [
        "spark_links_df.count()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yerPEcBGN2jF",
        "colab_type": "text"
      },
      "source": [
        "### Filtering Data\n",
        "\n",
        "Let's take a look at the .filter() method. As you might suspect, this is the Spark counterpart of SQL's WHERE clause. The .filter() method takes either an expression that would follow the WHERE clause of a SQL expression as a string, or a Spark Column of boolean (True/False) values.\n",
        "\n",
        "For example, the following two expressions will produce the same output:\n",
        "```\n",
        "flights.filter(\"air_time > 120\").show()\n",
        "flights.filter(flights.air_time > 120).show()\n",
        "```\n",
        "\n",
        "Notice that in the first case, we pass a string to .filter(). In SQL, we would write this filtering task as SELECT * FROM flights WHERE air_time > 120. Spark's .filter() can accept any expression that could go in the WHEREclause of a SQL query (in this case, \"air_time > 120\"), as long as it is passed as a string. Notice that in this case, we do not reference the name of the table in the string -- as we wouldn't in the SQL request.\n",
        "\n",
        "In the second case, we actually pass a column of boolean values to .filter(). Remember that flights.air_time > 120 returns a column of boolean values that has True in place of those records in flights.air_time that are over 120, and False otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhnmr2B1N2jH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e7205de2-5b6b-451c-957d-e5bb6c0229d6"
      },
      "source": [
        "# First let's filter the data by passing a string\n",
        "movie_id_over_30k = spark_links_df.filter(\"movieId > 30000\")\n",
        "movie_id_over_30k.show(10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|movieId| imdbId|tmdbId|\n",
            "+-------+-------+------+\n",
            "|  30659|0383534| 41171|\n",
            "|  30695|0316824| 23592|\n",
            "|  30698|0376568| 47614|\n",
            "|  30701|0059012|   986|\n",
            "|  30707|0405159|    70|\n",
            "|  30712|0044954| 31713|\n",
            "|  30721|0056062| 32041|\n",
            "|  30723|0100873| 55309|\n",
            "|  30742|0052218| 38724|\n",
            "|  30745|0361668| 12487|\n",
            "+-------+-------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tQN0qXjezqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ffe852c2-f683-402f-d292-8c8f98877d65"
      },
      "source": [
        "# Next let's filter by using a boolean expression\n",
        "movie_id_over_30k2 = spark_links_df.filter(spark_links_df.movieId > 30000)\n",
        "movie_id_over_30k2.show(10)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|movieId| imdbId|tmdbId|\n",
            "+-------+-------+------+\n",
            "|  30659|0383534| 41171|\n",
            "|  30695|0316824| 23592|\n",
            "|  30698|0376568| 47614|\n",
            "|  30701|0059012|   986|\n",
            "|  30707|0405159|    70|\n",
            "|  30712|0044954| 31713|\n",
            "|  30721|0056062| 32041|\n",
            "|  30723|0100873| 55309|\n",
            "|  30742|0052218| 38724|\n",
            "|  30745|0361668| 12487|\n",
            "+-------+-------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEnIDEwJN2jI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed3e4610-e9b4-44a1-9072-fc7ae95f97f8"
      },
      "source": [
        "movie_id_over_30k.count()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2VM1SS0N2jK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86f3139c-0b3c-421f-f5a9-f8cce8586b31"
      },
      "source": [
        "movie_id_over_30k2.count()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4OOCMhwN2jM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01096015-fe0d-449c-da5d-9e5ccf60175e"
      },
      "source": [
        "# Let's compare them to be sure\n",
        "movie_id_over_30k.count() == movie_id_over_30k2.count()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90YKQH5ON2jN",
        "colab_type": "text"
      },
      "source": [
        "### Selecting\n",
        "The Spark variant of SQL's SELECT is the .select() method. This method takes multiple arguments - one for each column you want to select. These arguments can either be the column name as a string (one for each column) or a column object (using the df.colName syntax). When you pass a column object, you can perform operations like addition or subtraction on the column to change the data contained in it, much like inside .withColumn().\n",
        "\n",
        "The difference between .select() and .withColumn() methods is that .select() returns only the columns you specify, while .withColumn() returns all the columns of the DataFrame in addition to the one you defined. It's often a good idea to drop columns you don't need at the beginning of an operation so that you're not dragging around extra data as you're wrangling. In this case, you would use .select() and not .withColumn()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrrt9qI2N2jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create a dataframe from the ratings csv file.\n",
        "spark_ratings_df = spark.read.csv('ratings.csv', header=True)\n",
        "\n",
        "# Let's add it to the session catalog\n",
        "spark_ratings_df.createOrReplaceTempView('spark_ratings_df')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LHsMedzlN2jP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "61483dfa-f44e-4dcf-c9d6-00e69789818e"
      },
      "source": [
        "# Finally let's see the shape and first 20 rows\n",
        "print(\"shape of spark_ratings_df is {} rows, and {} cols.\".format(spark_ratings_df.count(), len(spark_ratings_df.columns)))\n",
        "spark_ratings_df.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of spark_ratings_df is 22884377 rows, and 4 cols.\n",
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "|     2| 112552|   5.0|1436165496|\n",
            "|     2| 112556|   4.0|1436165499|\n",
            "|     3|    356|   4.0| 920587155|\n",
            "|     3|   2394|   4.0| 920586920|\n",
            "|     3|   2431|   5.0| 920586945|\n",
            "|     3|   2445|   4.0| 920586945|\n",
            "|     4|     16|   4.0|1037740142|\n",
            "|     4|     39|   4.0|1037740562|\n",
            "|     4|     45|   4.0|1037808019|\n",
            "|     4|     47|   2.0|1037739998|\n",
            "|     4|     94|   5.0|1037740486|\n",
            "|     4|    101|   4.0|1037737327|\n",
            "|     4|    246|   4.0|1037739164|\n",
            "|     4|    288|   2.0|1037737415|\n",
            "|     4|    296|   4.0|1037741922|\n",
            "+------+-------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2l7KyPWjN2jR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4bd6ac52-4697-47b1-e9f4-e0b826eb311b"
      },
      "source": [
        "# Select columns movieId and rating from spark_ratings_df by passing their string names. save same as movies1\n",
        "movies1 = spark_ratings_df.select(\"movieId\", \"rating\")\n",
        "movies1.show(5)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|movieId|rating|\n",
            "+-------+------+\n",
            "|    169|   2.5|\n",
            "|   2471|   3.0|\n",
            "|  48516|   5.0|\n",
            "|   2571|   3.5|\n",
            "| 109487|   4.0|\n",
            "+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n_Cyb-DN2jS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "43856040-d5dc-4f47-ad79-8928c58520c7"
      },
      "source": [
        "# Select columns userId and movieId from movies_df by using the column object syntanx. save same as movies2\n",
        "movies2 = spark_ratings_df.select(spark_ratings_df.userId, spark_ratings_df.movieId)\n",
        "movies2.show(5)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|userId|movieId|\n",
            "+------+-------+\n",
            "|     1|    169|\n",
            "|     1|   2471|\n",
            "|     1|  48516|\n",
            "|     2|   2571|\n",
            "|     2| 109487|\n",
            "+------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoiRiD-8N2jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's define and employ two filters for movies1 and 2\n",
        "filterA = movies2.movieId >= 100000\n",
        "filterB = movies1.rating == 4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Ewo5cSN2jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filterA_data = movies2.filter(filterA)\n",
        "filterB_data = movies1.filter(filterB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdiMqBN9N2jU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fa9b4f9f-eebf-4729-ac37-efe19b1e1ad4"
      },
      "source": [
        "filterA_data.show(5)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|userId|movieId|\n",
            "+------+-------+\n",
            "|     2| 109487|\n",
            "|     2| 112552|\n",
            "|     2| 112556|\n",
            "|     5| 112183|\n",
            "|     5| 112552|\n",
            "+------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47z-gSooN2jV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f6130369-70fd-4b84-8e7a-9034969d2fa8"
      },
      "source": [
        "filterB_data.show(5)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|movieId|rating|\n",
            "+-------+------+\n",
            "| 109487|   4.0|\n",
            "| 112556|   4.0|\n",
            "|    356|   4.0|\n",
            "|   2394|   4.0|\n",
            "|   2445|   4.0|\n",
            "+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-voYRwO_N2jW",
        "colab_type": "text"
      },
      "source": [
        "### Selecting II\n",
        "Similar to SQL, you can also use the .select() method to perform column-wise operations. When you're selecting a column using the df.colName notation, you can perform any column operation and the .select() method will return the transformed column. For example,\n",
        "```\n",
        "movies1.select(movies1.rating/5.0)\n",
        "```\n",
        "returns a column of ratings divided by 5. You can also use the .alias() method to rename a column you're selecting. <br>\n",
        "So if you wanted to .select() the column norm_weight (which isn't in your DataFrame) you could do\n",
        "```\n",
        "movies1.select((movies1.rating/5.0).alias(\"norm_weight\"))\n",
        "```\n",
        "The equivalent Spark DataFrame method .selectExpr() takes SQL expressions as a string:\n",
        "```\n",
        "movies1.selectExpr(\"rating/5.0 as norm_weight\")\n",
        "```\n",
        "with the SQL as keyword being equivalent to the .alias() method. To select multiple columns, you can pass multiple strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZxW3j0rN2jX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b184d97b-47bc-4248-b934-9f1622a6157c"
      },
      "source": [
        "# First let's create a copy of the spark_ratings_df\n",
        "new_spark_ratings_df = spark.table(\"spark_ratings_df\")\n",
        "new_spark_ratings_df.show(5)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zoKVcE1N2jY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4f118c15-480c-42bb-b22a-3b1debaa626a"
      },
      "source": [
        "norm_weight = new_spark_ratings_df.selectExpr(\"rating / 5.0 as norm_weight\")\n",
        "norm_weight.show(5)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|norm_weight|\n",
            "+-----------+\n",
            "|        0.5|\n",
            "|        0.6|\n",
            "|        1.0|\n",
            "|        0.7|\n",
            "|        0.8|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq8wkxN2hQdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "c25a9178-d4f8-4c2b-cc43-4e6d13da9874"
      },
      "source": [
        "# Let's see the new_spark_ratings_df again if norm_weight col is added\n",
        "new_spark_ratings_df.show()\n",
        "\n",
        "# It's not added as .select() does not alterate the data frame like .withcolumn()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "|     2| 112552|   5.0|1436165496|\n",
            "|     2| 112556|   4.0|1436165499|\n",
            "|     3|    356|   4.0| 920587155|\n",
            "|     3|   2394|   4.0| 920586920|\n",
            "|     3|   2431|   5.0| 920586945|\n",
            "|     3|   2445|   4.0| 920586945|\n",
            "|     4|     16|   4.0|1037740142|\n",
            "|     4|     39|   4.0|1037740562|\n",
            "|     4|     45|   4.0|1037808019|\n",
            "|     4|     47|   2.0|1037739998|\n",
            "|     4|     94|   5.0|1037740486|\n",
            "|     4|    101|   4.0|1037737327|\n",
            "|     4|    246|   4.0|1037739164|\n",
            "|     4|    288|   2.0|1037737415|\n",
            "|     4|    296|   4.0|1037741922|\n",
            "+------+-------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHDNcnrbN2jZ",
        "colab_type": "text"
      },
      "source": [
        "## IBM watson spark lab, part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St0GXQ9WN2jZ",
        "colab_type": "text"
      },
      "source": [
        "This notebook guides you through querying data with Spark, including how to create and use DataFrames, run SQL queries, apply functions to the results of SQL queries, join data from different data sources, and visualize data in graphs.\n",
        "\n",
        "This notebook uses pySpark, the Python API for Spark. Some knowledge of Python is recommended. This notebook runs on Python 3.6 with Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99F9NmP-N2ja",
        "colab_type": "text"
      },
      "source": [
        "### 1. Prepare the environment and the data\n",
        "Before you can run SQL queries on data in a Spark environment, you need to enable SQL processing and then move the data to the structured format of a DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i8IQW3-N2jb",
        "colab_type": "text"
      },
      "source": [
        "**1.1 Enable SQL processing**\n",
        "\n",
        "The preferred method to enable SQL processing with Spark 2.0 is to use the new SparkSession object, but you can also create a SQLContext object.\n",
        "\n",
        "Use the predefined Spark Context, sc, which contains the connection information for Spark, to create an SQLContext:\n",
        "The preferred method to enable SQL processing with Spark 2.0 is to use the new SparkSession object, but you can also create a SQLContext object.\n",
        "\n",
        "Use the predefined Spark Context, sc, which contains the connection information for Spark, to create an SQLContext:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQYoJQutN2jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ic-B7EN2jc",
        "colab_type": "text"
      },
      "source": [
        "**1.2 Download the data file**<br>\n",
        "You'll download a JSON file with data about world banks from GitHub. The data is adapted from this data set: http://data.worldbank.org/data-catalog/projects-portfolio.\n",
        "\n",
        "Remove any files with the same name as the file that you're going to download and then download the file from a URL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj8w3AXDN2jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "93a8d524-e989-4223-c065-d862e1d6d581"
      },
      "source": [
        "!rm world_bank.json.gz -f\n",
        "!wget https://raw.githubusercontent.com/bradenrc/sparksql_pot/master/world_bank.json.gz"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 19:30:40--  https://raw.githubusercontent.com/bradenrc/sparksql_pot/master/world_bank.json.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 446287 (436K) [application/octet-stream]\n",
            "Saving to: ‘world_bank.json.gz’\n",
            "\n",
            "\rworld_bank.json.gz    0%[                    ]       0  --.-KB/s               \rworld_bank.json.gz  100%[===================>] 435.83K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-01-31 19:30:41 (17.8 MB/s) - ‘world_bank.json.gz’ saved [446287/446287]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7n6UuZNN2jd",
        "colab_type": "text"
      },
      "source": [
        "**1.3 Create a DataFrame**<br>\n",
        "Instead of creating an RDD to read the file, you'll create a Spark DataFrame. Unlike an RDD, a DataFrame creates a schema around the data, which supplies the necessary structure for SQL queries. A self-describing format like JSON is ideal for DataFrames, but many other file types are supported, including text (CSV) and Parquet.\n",
        "\n",
        "Create a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo64yNR9N2jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example1_df = sqlContext.read.json(\"world_bank.json.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg95GzUfjatv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "f46c9071-e410-498e-b319-627db089e2c0"
      },
      "source": [
        "# show the first five rows\n",
        "example1_df.show(5)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+------------------+--------------------+------------------------+--------+-----------+-------+----------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+------+------+--------------------+--------------------+--------------------+-----------+---------+------------+--------------------+\n",
            "|                 _id|approvalfy|board_approval_month|   boardapprovaldate|            borrower|         closingdate|    country_namecode|countrycode|         countryname|  countryshortname|               docty|envassesmentcategorycode|grantamt|ibrdcommamt|     id|idacommamt|           impagency|        lendinginstr|lendinginstrtype|lendprojectcost| majorsector_percent|   mjsector_namecode|             mjtheme|    mjtheme_namecode|mjthemecode|prodline|        prodlinetext|productlinetype|    project_abstract|        project_name|         projectdocs|projectfinancialtype|projectstatusdisplay|          regionname|              sector|             sector1|             sector2|             sector3|             sector4|     sector_namecode| sectorcode|source|status|supplementprojectflg|              theme1|      theme_namecode|  themecode| totalamt|totalcommamt|                 url|\n",
            "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+------------------+--------------------+------------------------+--------+-----------+-------+----------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+------+------+--------------------+--------------------+--------------------+-----------+---------+------------+--------------------+\n",
            "|[52b213b38594d8a2...|      1999|            November|2013-11-12T00:00:00Z|FEDERAL DEMOCRATI...|2018-07-07T00:00:00Z|Federal Democrati...|         ET|Federal Democrati...|          Ethiopia|Project Informati...|                       C|       0|          0|P129828| 130000000|MINISTRY OF EDUCA...|Investment Projec...|              IN|      550000000|[[Education, 46],...|[[EX, Education],...| [Human development]|[[8, Human develo...|       8,11|      PE|            IBRD/IDA|              L|[The development ...|Ethiopia General ...|[[28-AUG-2013, PI...|                 IDA|              Active|              Africa|[[Primary educati...|[Primary educatio...|[Secondary educat...|[Public administr...|[Tertiary educati...|[[EP, Primary edu...|ET,BS,ES,EP|  IBRD|Active|                   N|[Education for al...|[[65, Education f...|         65|130000000|   130000000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2015|            November|2013-11-04T00:00:00Z|GOVERNMENT OF TUN...|                null|Republic of Tunis...|         TN| Republic of Tunisia|           Tunisia|Project Informati...|                       C| 4700000|          0|P144674|         0| MINISTRY OF FINANCE|Specific Investme...|              IN|        5700000|[[Public Administ...|[[BX, Public Admi...|[Economic managem...|[[1, Economic man...|        1,6|      RE|Recipient Execute...|              L|                null|TN: DTF Social Pr...|[[29-MAR-2013, PI...|               OTHER|              Active|Middle East and N...|[[Public administ...|[Public administr...|[General public a...|                null|                null|[[BS, Public admi...|      BZ,BS|  IBRD|Active|                   N|[Other economic m...|[[24, Other econo...|      54,24|        0|     4700000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2014|            November|2013-11-01T00:00:00Z|MINISTRY OF FINAN...|                null|         Tuvalu!$!TV|         TV|              Tuvalu|            Tuvalu|Resettlement Plan...|                       B|       0|          0|P145310|   6060000|MINISTRY OF TRANS...|Investment Projec...|              IN|        6060000|[[Transportation,...|[[TX, Transportat...|[Trade and integr...|[[5, Trade and in...|   5,2,11,6|      PE|            IBRD/IDA|              L|                null|Tuvalu Aviation I...|[[21-OCT-2013, RP...|                 IDA|              Active|East Asia and Pac...|[[Rural and Inter...|[Rural and Inter-...|                null|                null|                null|[[TI, Rural and I...|         TI|  IBRD|Active|                   Y|[Regional integra...|[[47, Regional in...|52,81,25,47|  6060000|     6060000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2014|             October|2013-10-31T00:00:00Z|MIN. OF PLANNING ...|                null|Republic of Yemen...|         RY|   Republic of Yemen|Yemen, Republic of|Procurement Plan,...|                       C| 1500000|          0|P144665|         0|LABOR INTENSIVE P...|Technical Assista...|              IN|        1500000|[[Health and othe...|[[JX, Health and ...|[Social dev/gende...|[[7, Social dev/g...|        7,7|      RE|Recipient Execute...|              L|                null|Gov't and Civil S...|[[15-MAY-2013, PR...|               OTHER|              Active|Middle East and N...|[[Other social se...|[Other social ser...|                null|                null|                null|[[JB, Other socia...|         JB|  IBRD|Active|                   N|[Participation an...|[[57, Participati...|      59,57|        0|     1500000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2014|             October|2013-10-31T00:00:00Z| MINISTRY OF FINANCE|2019-04-30T00:00:00Z|Kingdom of Lesoth...|         LS|  Kingdom of Lesotho|           Lesotho|Project Informati...|                       B|       0|          0|P144933|  13100000|MINISTRY OF TRADE...|Investment Projec...|              IN|       15000000|[[Industry and tr...|[[YX, Industry an...|[Trade and integr...|[[5, Trade and in...|        5,4|      PE|            IBRD/IDA|              L|[The development ...|Second Private Se...|[[06-SEP-2013, PI...|                 IDA|              Active|              Africa|[[General industr...|[General industry...|[Other industry, 40]|   [SME Finance, 10]|                null|[[YZ, General ind...|   FH,YW,YZ|  IBRD|Active|                   N|[Export developme...|[[45, Export deve...|      41,45| 13100000|    13100000|http://www.worldb...|\n",
            "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+------------------+--------------------+------------------------+--------+-----------+-------+----------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+------+------+--------------------+--------------------+--------------------+-----------+---------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7-Qyt-zN2jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e970833-f616-424f-d969-fbd31ff75eaa"
      },
      "source": [
        "# Print the schema to see how Spark SQL inferred the shape of the data:\n",
        "print(example1_df.printSchema())"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _id: struct (nullable = true)\n",
            " |    |-- $oid: string (nullable = true)\n",
            " |-- approvalfy: string (nullable = true)\n",
            " |-- board_approval_month: string (nullable = true)\n",
            " |-- boardapprovaldate: string (nullable = true)\n",
            " |-- borrower: string (nullable = true)\n",
            " |-- closingdate: string (nullable = true)\n",
            " |-- country_namecode: string (nullable = true)\n",
            " |-- countrycode: string (nullable = true)\n",
            " |-- countryname: string (nullable = true)\n",
            " |-- countryshortname: string (nullable = true)\n",
            " |-- docty: string (nullable = true)\n",
            " |-- envassesmentcategorycode: string (nullable = true)\n",
            " |-- grantamt: long (nullable = true)\n",
            " |-- ibrdcommamt: long (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- idacommamt: long (nullable = true)\n",
            " |-- impagency: string (nullable = true)\n",
            " |-- lendinginstr: string (nullable = true)\n",
            " |-- lendinginstrtype: string (nullable = true)\n",
            " |-- lendprojectcost: long (nullable = true)\n",
            " |-- majorsector_percent: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- Name: string (nullable = true)\n",
            " |    |    |-- Percent: long (nullable = true)\n",
            " |-- mjsector_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- mjtheme: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- mjtheme_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- mjthemecode: string (nullable = true)\n",
            " |-- prodline: string (nullable = true)\n",
            " |-- prodlinetext: string (nullable = true)\n",
            " |-- productlinetype: string (nullable = true)\n",
            " |-- project_abstract: struct (nullable = true)\n",
            " |    |-- cdata: string (nullable = true)\n",
            " |-- project_name: string (nullable = true)\n",
            " |-- projectdocs: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- DocDate: string (nullable = true)\n",
            " |    |    |-- DocType: string (nullable = true)\n",
            " |    |    |-- DocTypeDesc: string (nullable = true)\n",
            " |    |    |-- DocURL: string (nullable = true)\n",
            " |    |    |-- EntityID: string (nullable = true)\n",
            " |-- projectfinancialtype: string (nullable = true)\n",
            " |-- projectstatusdisplay: string (nullable = true)\n",
            " |-- regionname: string (nullable = true)\n",
            " |-- sector: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- Name: string (nullable = true)\n",
            " |-- sector1: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector2: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector3: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector4: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- sectorcode: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- supplementprojectflg: string (nullable = true)\n",
            " |-- theme1: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- theme_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- themecode: string (nullable = true)\n",
            " |-- totalamt: long (nullable = true)\n",
            " |-- totalcommamt: long (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiN8-FYyN2jg",
        "colab_type": "text"
      },
      "source": [
        "Now look at the first two rows of data.\n",
        "<br>You can run the simple command print example1_df.take(2), however, for readability, run the following command to include a row of asterisks in between the data rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY-wtz0IN2jg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "71b7f347-2f34-4ed1-ae44-234f1e9cb16f"
      },
      "source": [
        "for row in example1_df.take(2):\n",
        "    print(row)\n",
        "    print(\"*\" * 20)\n",
        "    "
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row(_id=Row($oid='52b213b38594d8a2be17c780'), approvalfy='1999', board_approval_month='November', boardapprovaldate='2013-11-12T00:00:00Z', borrower='FEDERAL DEMOCRATIC REPUBLIC OF ETHIOPIA', closingdate='2018-07-07T00:00:00Z', country_namecode='Federal Democratic Republic of Ethiopia!$!ET', countrycode='ET', countryname='Federal Democratic Republic of Ethiopia', countryshortname='Ethiopia', docty='Project Information Document,Indigenous Peoples Plan,Project Information Document', envassesmentcategorycode='C', grantamt=0, ibrdcommamt=0, id='P129828', idacommamt=130000000, impagency='MINISTRY OF EDUCATION', lendinginstr='Investment Project Financing', lendinginstrtype='IN', lendprojectcost=550000000, majorsector_percent=[Row(Name='Education', Percent=46), Row(Name='Education', Percent=26), Row(Name='Public Administration, Law, and Justice', Percent=16), Row(Name='Education', Percent=12)], mjsector_namecode=[Row(code='EX', name='Education'), Row(code='EX', name='Education'), Row(code='BX', name='Public Administration, Law, and Justice'), Row(code='EX', name='Education')], mjtheme=['Human development'], mjtheme_namecode=[Row(code='8', name='Human development'), Row(code='11', name='')], mjthemecode='8,11', prodline='PE', prodlinetext='IBRD/IDA', productlinetype='L', project_abstract=Row(cdata='The development objective of the Second Phase of General Education Quality Improvement Project for Ethiopia is to improve learning conditions in primary and secondary schools and strengthen institutions at different levels of educational administration. The project has six components. The first component is curriculum, textbooks, assessment, examinations, and inspection. This component will support improvement of learning conditions in grades KG-12 by providing increased access to teaching and learning materials and through improvements to the curriculum by assessing the strengths and weaknesses of the current curriculum. This component has following four sub-components: (i) curriculum reform and implementation; (ii) teaching and learning materials; (iii) assessment and examinations; and (iv) inspection. The second component is teacher development program (TDP). This component will support improvements in learning conditions in both primary and secondary schools by advancing the quality of teaching in general education through: (a) enhancing the training of pre-service teachers in teacher education institutions; and (b) improving the quality of in-service teacher training. This component has following three sub-components: (i) pre-service teacher training; (ii) in-service teacher training; and (iii) licensing and relicensing of teachers and school leaders. The third component is school improvement plan. This component will support the strengthening of school planning in order to improve learning outcomes, and to partly fund the school improvement plans through school grants. It has following two sub-components: (i) school improvement plan; and (ii) school grants. The fourth component is management and capacity building, including education management information systems (EMIS). This component will support management and capacity building aspect of the project. This component has following three sub-components: (i) capacity building for education planning and management; (ii) capacity building for school planning and management; and (iii) EMIS. The fifth component is improving the quality of learning and teaching in secondary schools and universities through the use of information and communications technology (ICT). It has following five sub-components: (i) national policy and institution for ICT in general education; (ii) national ICT infrastructure improvement plan for general education; (iii) develop an integrated monitoring, evaluation, and learning system specifically for the ICT component; (iv) teacher professional development in the use of ICT; and (v) provision of limited number of e-Braille display readers with the possibility to scale up to all secondary education schools based on the successful implementation and usage of the readers. The sixth component is program coordination, monitoring and evaluation, and communication. It will support institutional strengthening by developing capacities in all aspects of program coordination, monitoring and evaluation; a new sub-component on communications will support information sharing for better management and accountability. It has following three sub-components: (i) program coordination; (ii) monitoring and evaluation (M and E); and (iii) communication.'), project_name='Ethiopia General Education Quality Improvement Project II', projectdocs=[Row(DocDate='28-AUG-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=090224b081e545fb_1_0', EntityID='090224b081e545fb_1_0'), Row(DocDate='01-JUL-2013', DocType='IP', DocTypeDesc='Indigenous Peoples Plan (IP),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000442464_20130920111729', EntityID='000442464_20130920111729'), Row(DocDate='22-NOV-2012', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=090224b0817b19e2_1_0', EntityID='090224b0817b19e2_1_0')], projectfinancialtype='IDA', projectstatusdisplay='Active', regionname='Africa', sector=[Row(Name='Primary education'), Row(Name='Secondary education'), Row(Name='Public administration- Other social services'), Row(Name='Tertiary education')], sector1=Row(Name='Primary education', Percent=46), sector2=Row(Name='Secondary education', Percent=26), sector3=Row(Name='Public administration- Other social services', Percent=16), sector4=Row(Name='Tertiary education', Percent=12), sector_namecode=[Row(code='EP', name='Primary education'), Row(code='ES', name='Secondary education'), Row(code='BS', name='Public administration- Other social services'), Row(code='ET', name='Tertiary education')], sectorcode='ET,BS,ES,EP', source='IBRD', status='Active', supplementprojectflg='N', theme1=Row(Name='Education for all', Percent=100), theme_namecode=[Row(code='65', name='Education for all')], themecode='65', totalamt=130000000, totalcommamt=130000000, url='http://www.worldbank.org/projects/P129828/ethiopia-general-education-quality-improvement-project-ii?lang=en')\n",
            "********************\n",
            "Row(_id=Row($oid='52b213b38594d8a2be17c781'), approvalfy='2015', board_approval_month='November', boardapprovaldate='2013-11-04T00:00:00Z', borrower='GOVERNMENT OF TUNISIA', closingdate=None, country_namecode='Republic of Tunisia!$!TN', countrycode='TN', countryname='Republic of Tunisia', countryshortname='Tunisia', docty='Project Information Document,Integrated Safeguards Data Sheet,Integrated Safeguards Data Sheet,Project Information Document,Integrated Safeguards Data Sheet,Project Information Document', envassesmentcategorycode='C', grantamt=4700000, ibrdcommamt=0, id='P144674', idacommamt=0, impagency='MINISTRY OF FINANCE', lendinginstr='Specific Investment Loan', lendinginstrtype='IN', lendprojectcost=5700000, majorsector_percent=[Row(Name='Public Administration, Law, and Justice', Percent=70), Row(Name='Public Administration, Law, and Justice', Percent=30)], mjsector_namecode=[Row(code='BX', name='Public Administration, Law, and Justice'), Row(code='BX', name='Public Administration, Law, and Justice')], mjtheme=['Economic management', 'Social protection and risk management'], mjtheme_namecode=[Row(code='1', name='Economic management'), Row(code='6', name='Social protection and risk management')], mjthemecode='1,6', prodline='RE', prodlinetext='Recipient Executed Activities', productlinetype='L', project_abstract=None, project_name='TN: DTF Social Protection Reforms Support', projectdocs=[Row(DocDate='29-MAR-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000333037_20131024115616', EntityID='000333037_20131024115616'), Row(DocDate='29-MAR-2013', DocType='ISDS', DocTypeDesc='Integrated Safeguards Data Sheet (ISDS),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000356161_20131024151611', EntityID='000356161_20131024151611'), Row(DocDate='29-MAR-2013', DocType='ISDS', DocTypeDesc='Integrated Safeguards Data Sheet (ISDS),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000442464_20131031112136', EntityID='000442464_20131031112136'), Row(DocDate='29-MAR-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000333037_20131031105716', EntityID='000333037_20131031105716'), Row(DocDate='16-JAN-2013', DocType='ISDS', DocTypeDesc='Integrated Safeguards Data Sheet (ISDS),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000356161_20130305113209', EntityID='000356161_20130305113209'), Row(DocDate='16-JAN-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000356161_20130305113716', EntityID='000356161_20130305113716')], projectfinancialtype='OTHER', projectstatusdisplay='Active', regionname='Middle East and North Africa', sector=[Row(Name='Public administration- Other social services'), Row(Name='General public administration sector')], sector1=Row(Name='Public administration- Other social services', Percent=70), sector2=Row(Name='General public administration sector', Percent=30), sector3=None, sector4=None, sector_namecode=[Row(code='BS', name='Public administration- Other social services'), Row(code='BZ', name='General public administration sector')], sectorcode='BZ,BS', source='IBRD', status='Active', supplementprojectflg='N', theme1=Row(Name='Other economic management', Percent=30), theme_namecode=[Row(code='24', name='Other economic management'), Row(code='54', name='Social safety nets')], themecode='54,24', totalamt=0, totalcommamt=4700000, url='http://www.worldbank.org/projects/P144674?lang=en')\n",
            "********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pz5VKsbN2jj",
        "colab_type": "text"
      },
      "source": [
        "**1.4 Create a table**<br>\n",
        "SQL statements must be run against a table. Create a table that's a pointer to the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W66mOb8zN2jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example1_df.registerTempTable(\"world_bank\")  ## The table world_bank is now a pointer to the data frame example1_df."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iTN9JWNN2jl",
        "colab_type": "text"
      },
      "source": [
        "Let's print out the current tables and see if world_bank is included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lSV5_3tN2jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "64ef4874-c0b9-4d3a-a827-104b27e98ff8"
      },
      "source": [
        "print(spark.catalog.listTables())"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Table(name='spark_links_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='spark_ratings_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='spark_tags_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True), Table(name='world_bank', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5yrrVfDln0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try using the .createOrReplaceTempView() method\n",
        "\n",
        "example1_df.createOrReplaceTempView(\"world_bank\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJTjPpUBl6dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c13522cf-7f56-4728-e71d-3ec4e374edf6"
      },
      "source": [
        "# Let's see the lists of tables\n",
        "spark.catalog.listTables()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='spark_links_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='spark_ratings_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='spark_tags_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='world_bank', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa1kIaQHN2jn",
        "colab_type": "text"
      },
      "source": [
        "## 2. Run SQL queries\n",
        "\n",
        "You must define a new DataFrame for the results of the SQL query and put the SQL statement inside the sqlContext.sql() method.\n",
        "\n",
        "Run the following cell to select all columns from the table and print information about the resulting DataFrame and schema of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaA5CjZBN2jn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f899c2d9-5af2-43af-a26e-f4babca052d0"
      },
      "source": [
        "temp_df = sqlContext.sql(\"select * from world_bank\")\n",
        "print(type(temp_df))\n",
        "print(\"*\" * 20)\n",
        "temp_df.show(5)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "********************\n",
            "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+------------------+--------------------+------------------------+--------+-----------+-------+----------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+------+------+--------------------+--------------------+--------------------+-----------+---------+------------+--------------------+\n",
            "|                 _id|approvalfy|board_approval_month|   boardapprovaldate|            borrower|         closingdate|    country_namecode|countrycode|         countryname|  countryshortname|               docty|envassesmentcategorycode|grantamt|ibrdcommamt|     id|idacommamt|           impagency|        lendinginstr|lendinginstrtype|lendprojectcost| majorsector_percent|   mjsector_namecode|             mjtheme|    mjtheme_namecode|mjthemecode|prodline|        prodlinetext|productlinetype|    project_abstract|        project_name|         projectdocs|projectfinancialtype|projectstatusdisplay|          regionname|              sector|             sector1|             sector2|             sector3|             sector4|     sector_namecode| sectorcode|source|status|supplementprojectflg|              theme1|      theme_namecode|  themecode| totalamt|totalcommamt|                 url|\n",
            "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+------------------+--------------------+------------------------+--------+-----------+-------+----------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+------+------+--------------------+--------------------+--------------------+-----------+---------+------------+--------------------+\n",
            "|[52b213b38594d8a2...|      1999|            November|2013-11-12T00:00:00Z|FEDERAL DEMOCRATI...|2018-07-07T00:00:00Z|Federal Democrati...|         ET|Federal Democrati...|          Ethiopia|Project Informati...|                       C|       0|          0|P129828| 130000000|MINISTRY OF EDUCA...|Investment Projec...|              IN|      550000000|[[Education, 46],...|[[EX, Education],...| [Human development]|[[8, Human develo...|       8,11|      PE|            IBRD/IDA|              L|[The development ...|Ethiopia General ...|[[28-AUG-2013, PI...|                 IDA|              Active|              Africa|[[Primary educati...|[Primary educatio...|[Secondary educat...|[Public administr...|[Tertiary educati...|[[EP, Primary edu...|ET,BS,ES,EP|  IBRD|Active|                   N|[Education for al...|[[65, Education f...|         65|130000000|   130000000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2015|            November|2013-11-04T00:00:00Z|GOVERNMENT OF TUN...|                null|Republic of Tunis...|         TN| Republic of Tunisia|           Tunisia|Project Informati...|                       C| 4700000|          0|P144674|         0| MINISTRY OF FINANCE|Specific Investme...|              IN|        5700000|[[Public Administ...|[[BX, Public Admi...|[Economic managem...|[[1, Economic man...|        1,6|      RE|Recipient Execute...|              L|                null|TN: DTF Social Pr...|[[29-MAR-2013, PI...|               OTHER|              Active|Middle East and N...|[[Public administ...|[Public administr...|[General public a...|                null|                null|[[BS, Public admi...|      BZ,BS|  IBRD|Active|                   N|[Other economic m...|[[24, Other econo...|      54,24|        0|     4700000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2014|            November|2013-11-01T00:00:00Z|MINISTRY OF FINAN...|                null|         Tuvalu!$!TV|         TV|              Tuvalu|            Tuvalu|Resettlement Plan...|                       B|       0|          0|P145310|   6060000|MINISTRY OF TRANS...|Investment Projec...|              IN|        6060000|[[Transportation,...|[[TX, Transportat...|[Trade and integr...|[[5, Trade and in...|   5,2,11,6|      PE|            IBRD/IDA|              L|                null|Tuvalu Aviation I...|[[21-OCT-2013, RP...|                 IDA|              Active|East Asia and Pac...|[[Rural and Inter...|[Rural and Inter-...|                null|                null|                null|[[TI, Rural and I...|         TI|  IBRD|Active|                   Y|[Regional integra...|[[47, Regional in...|52,81,25,47|  6060000|     6060000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2014|             October|2013-10-31T00:00:00Z|MIN. OF PLANNING ...|                null|Republic of Yemen...|         RY|   Republic of Yemen|Yemen, Republic of|Procurement Plan,...|                       C| 1500000|          0|P144665|         0|LABOR INTENSIVE P...|Technical Assista...|              IN|        1500000|[[Health and othe...|[[JX, Health and ...|[Social dev/gende...|[[7, Social dev/g...|        7,7|      RE|Recipient Execute...|              L|                null|Gov't and Civil S...|[[15-MAY-2013, PR...|               OTHER|              Active|Middle East and N...|[[Other social se...|[Other social ser...|                null|                null|                null|[[JB, Other socia...|         JB|  IBRD|Active|                   N|[Participation an...|[[57, Participati...|      59,57|        0|     1500000|http://www.worldb...|\n",
            "|[52b213b38594d8a2...|      2014|             October|2013-10-31T00:00:00Z| MINISTRY OF FINANCE|2019-04-30T00:00:00Z|Kingdom of Lesoth...|         LS|  Kingdom of Lesotho|           Lesotho|Project Informati...|                       B|       0|          0|P144933|  13100000|MINISTRY OF TRADE...|Investment Projec...|              IN|       15000000|[[Industry and tr...|[[YX, Industry an...|[Trade and integr...|[[5, Trade and in...|        5,4|      PE|            IBRD/IDA|              L|[The development ...|Second Private Se...|[[06-SEP-2013, PI...|                 IDA|              Active|              Africa|[[General industr...|[General industry...|[Other industry, 40]|   [SME Finance, 10]|                null|[[YZ, General ind...|   FH,YW,YZ|  IBRD|Active|                   N|[Export developme...|[[45, Export deve...|      41,45| 13100000|    13100000|http://www.worldb...|\n",
            "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+------------------+--------------------+------------------------+--------+-----------+-------+----------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+------+------+--------------------+--------------------+--------------------+-----------+---------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RxKGSPPN2jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f72bc17e-5f93-40f0-f92d-bf7a2fd09df6"
      },
      "source": [
        "# what are the column names and number of columns in the world_bank table(temp_df)\n",
        "print(\"Number of cols are {}\".format(len(temp_df.columns)))\n",
        "print(\"Number of rows are {}\".format(temp_df.count()))\n",
        "print(\"*\" * 20)\n",
        "print(temp_df.columns)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of cols are 50\n",
            "Number of rows are 500\n",
            "********************\n",
            "['_id', 'approvalfy', 'board_approval_month', 'boardapprovaldate', 'borrower', 'closingdate', 'country_namecode', 'countrycode', 'countryname', 'countryshortname', 'docty', 'envassesmentcategorycode', 'grantamt', 'ibrdcommamt', 'id', 'idacommamt', 'impagency', 'lendinginstr', 'lendinginstrtype', 'lendprojectcost', 'majorsector_percent', 'mjsector_namecode', 'mjtheme', 'mjtheme_namecode', 'mjthemecode', 'prodline', 'prodlinetext', 'productlinetype', 'project_abstract', 'project_name', 'projectdocs', 'projectfinancialtype', 'projectstatusdisplay', 'regionname', 'sector', 'sector1', 'sector2', 'sector3', 'sector4', 'sector_namecode', 'sectorcode', 'source', 'status', 'supplementprojectflg', 'theme1', 'theme_namecode', 'themecode', 'totalamt', 'totalcommamt', 'url']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2jGeHGLN2jq",
        "colab_type": "text"
      },
      "source": [
        "The first print command shows that the DataFrame is a Spark DataFrame. The last print command shows the column names and data types of the DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgV4N5HN2jq",
        "colab_type": "text"
      },
      "source": [
        "**2.1 Display query results with a pandas DataFrame**<br>\n",
        "The print command doesn't show the data in a useful format. Instead of creating a Spark DataFrame, use the pandas open-source data analytics library to create a pandas DataFrame that shows the data in a table.\n",
        "\n",
        "Import the pandas library and use the .toPandas() method to show the query results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECLULO9-N2jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6e1c598a-8efa-4339-8737-176880358cb5"
      },
      "source": [
        "sqlContext.sql(\"select id, borrower from world_bank limit 5\").toPandas()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>borrower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P129828</td>\n",
              "      <td>FEDERAL DEMOCRATIC REPUBLIC OF ETHIOPIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P144674</td>\n",
              "      <td>GOVERNMENT OF TUNISIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P145310</td>\n",
              "      <td>MINISTRY OF FINANCE AND ECONOMIC DEVEL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P144665</td>\n",
              "      <td>MIN. OF PLANNING AND INT'L COOPERATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P144933</td>\n",
              "      <td>MINISTRY OF FINANCE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                 borrower\n",
              "0  P129828  FEDERAL DEMOCRATIC REPUBLIC OF ETHIOPIA\n",
              "1  P144674                    GOVERNMENT OF TUNISIA\n",
              "2  P145310   MINISTRY OF FINANCE AND ECONOMIC DEVEL\n",
              "3  P144665   MIN. OF PLANNING AND INT'L COOPERATION\n",
              "4  P144933                      MINISTRY OF FINANCE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jPOwOnsN2js",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Run a group by query\n",
        "You can make your SQL queries easier to read by using the query keyword and surrounding the SQL query with \"\"\" on separate lines.\n",
        "\n",
        "Calculate a count of projects by region:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAUURGXdN2js",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "ddcb98eb-f420-422a-b661-3e1c2f731c73"
      },
      "source": [
        "query = \"\"\"\n",
        "select regionname, \n",
        "count(*) as project_count from world_bank\n",
        "group by regionname order by count(*) desc\n",
        "\n",
        "\"\"\"\n",
        "#sqlContext.sql(query).toPandas()\n",
        "spark.sql(query).toPandas()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>regionname</th>\n",
              "      <th>project_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Africa</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>East Asia and Pacific</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Europe and Central Asia</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>South Asia</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Middle East and North Africa</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Latin America and Caribbean</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Other</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     regionname  project_count\n",
              "0                        Africa            152\n",
              "1         East Asia and Pacific            100\n",
              "2       Europe and Central Asia             74\n",
              "3                    South Asia             65\n",
              "4  Middle East and North Africa             54\n",
              "5   Latin America and Caribbean             53\n",
              "6                         Other              2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er1tEAqeN2jt",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Run a subselect query\n",
        "You can run subselect queries.\n",
        "\n",
        "Calculate a count of projects by region again, but this time using a subselect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlvQI8GrN2jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "daed0e81-cf13-46ca-d1ba-a9fed9c5766b"
      },
      "source": [
        "query = \"\"\"\n",
        "select * from\n",
        "    (select\n",
        "        regionname ,\n",
        "        count(*) as project_count\n",
        "    from world_bank\n",
        "    group by regionname \n",
        "    order by count(*) desc) table_alias\n",
        "limit 5\n",
        "\"\"\"\n",
        "\n",
        "sqlContext.sql(query).toPandas()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>regionname</th>\n",
              "      <th>project_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Africa</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>East Asia and Pacific</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Europe and Central Asia</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>South Asia</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Middle East and North Africa</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     regionname  project_count\n",
              "0                        Africa            152\n",
              "1         East Asia and Pacific            100\n",
              "2       Europe and Central Asia             74\n",
              "3                    South Asia             65\n",
              "4  Middle East and North Africa             54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcBSneZiN2ju",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 Return nested JSON field values\n",
        "With JSON data, you can select the values of nested fields with dot notation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cDTCnFu3N2ju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2827cd0a-22ac-4677-ea8a-4c8493d9f312"
      },
      "source": [
        "example1_df.printSchema()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _id: struct (nullable = true)\n",
            " |    |-- $oid: string (nullable = true)\n",
            " |-- approvalfy: string (nullable = true)\n",
            " |-- board_approval_month: string (nullable = true)\n",
            " |-- boardapprovaldate: string (nullable = true)\n",
            " |-- borrower: string (nullable = true)\n",
            " |-- closingdate: string (nullable = true)\n",
            " |-- country_namecode: string (nullable = true)\n",
            " |-- countrycode: string (nullable = true)\n",
            " |-- countryname: string (nullable = true)\n",
            " |-- countryshortname: string (nullable = true)\n",
            " |-- docty: string (nullable = true)\n",
            " |-- envassesmentcategorycode: string (nullable = true)\n",
            " |-- grantamt: long (nullable = true)\n",
            " |-- ibrdcommamt: long (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- idacommamt: long (nullable = true)\n",
            " |-- impagency: string (nullable = true)\n",
            " |-- lendinginstr: string (nullable = true)\n",
            " |-- lendinginstrtype: string (nullable = true)\n",
            " |-- lendprojectcost: long (nullable = true)\n",
            " |-- majorsector_percent: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- Name: string (nullable = true)\n",
            " |    |    |-- Percent: long (nullable = true)\n",
            " |-- mjsector_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- mjtheme: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- mjtheme_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- mjthemecode: string (nullable = true)\n",
            " |-- prodline: string (nullable = true)\n",
            " |-- prodlinetext: string (nullable = true)\n",
            " |-- productlinetype: string (nullable = true)\n",
            " |-- project_abstract: struct (nullable = true)\n",
            " |    |-- cdata: string (nullable = true)\n",
            " |-- project_name: string (nullable = true)\n",
            " |-- projectdocs: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- DocDate: string (nullable = true)\n",
            " |    |    |-- DocType: string (nullable = true)\n",
            " |    |    |-- DocTypeDesc: string (nullable = true)\n",
            " |    |    |-- DocURL: string (nullable = true)\n",
            " |    |    |-- EntityID: string (nullable = true)\n",
            " |-- projectfinancialtype: string (nullable = true)\n",
            " |-- projectstatusdisplay: string (nullable = true)\n",
            " |-- regionname: string (nullable = true)\n",
            " |-- sector: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- Name: string (nullable = true)\n",
            " |-- sector1: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector2: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector3: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector4: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- sector_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- sectorcode: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- supplementprojectflg: string (nullable = true)\n",
            " |-- theme1: struct (nullable = true)\n",
            " |    |-- Name: string (nullable = true)\n",
            " |    |-- Percent: long (nullable = true)\n",
            " |-- theme_namecode: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- code: string (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |-- themecode: string (nullable = true)\n",
            " |-- totalamt: long (nullable = true)\n",
            " |-- totalcommamt: long (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgVFlLk3n8g6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "fa01dc54-a552-46ca-dc54-cdb576338b78"
      },
      "source": [
        "query = \"select majorsector_percent.name from world_bank limit 10\"\n",
        "spark.sql(query).toPandas()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Education, Education, Public Administration, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Public Administration, Law, and Justice, Publ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Transportation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Health and other social services]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Industry and trade, Industry and trade, Finance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[Health and other social services]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[Transportation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[Energy and mining]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[Transportation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[Public Administration, Law, and Justice, Publ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name\n",
              "0  [Education, Education, Public Administration, ...\n",
              "1  [Public Administration, Law, and Justice, Publ...\n",
              "2                                   [Transportation]\n",
              "3                 [Health and other social services]\n",
              "4  [Industry and trade, Industry and trade, Finance]\n",
              "5                 [Health and other social services]\n",
              "6                                   [Transportation]\n",
              "7                                [Energy and mining]\n",
              "8                                   [Transportation]\n",
              "9  [Public Administration, Law, and Justice, Publ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCKGopOyN2jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a4f334bc-1f92-45b5-d1b0-15cf6ca2d09f"
      },
      "source": [
        "query = \"select theme_namecode.name from world_bank limit 5\"\n",
        "sqlContext.sql(query).show()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                name|\n",
            "+--------------------+\n",
            "| [Education for all]|\n",
            "|[Other economic m...|\n",
            "|[Regional integra...|\n",
            "|[Participation an...|\n",
            "|[Export developme...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzIUjoChpQbu",
        "colab_type": "text"
      },
      "source": [
        "## DataCamp_Aggregating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR8RQ1kIpvOc",
        "colab_type": "text"
      },
      "source": [
        "All of the common aggregation methods, like .min(), .max(), and .count() are GroupedData methods. These are created by calling the .groupBy() DataFrame method. You'll learn exactly what that means in a few exercises. For now, all you have to do to use these functions is call that method on your DataFrame. For example, to find the minimum value of a column, col, in a DataFrame, df, you could do:\n",
        "```\n",
        "df.groupBy().min(\"col\").show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt29F-cBpaxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "04db3673-91be-4033-a726-2e4496f24b14"
      },
      "source": [
        "new_spark_ratings_df.show(5)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davXHbhVrbDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1b7bf901-913d-48bd-fa49-c8816e76d2a4"
      },
      "source": [
        "# Let's print it's schema\n",
        "new_spark_ratings_df.printSchema()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: string (nullable = true)\n",
            " |-- movieId: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o17Bo6LarquG",
        "colab_type": "text"
      },
      "source": [
        "We can see that userId, movieId and rating columns are all strings. We need change UserId and movieId to integer and rating to float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KROx-KVlqD6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "ce300e31-ce83-4ae3-febb-cf5dfc0b8198"
      },
      "source": [
        "# Changing column names using the .cast() function.\n",
        "for col_name in new_spark_ratings_df.columns[:-1]:\n",
        "    if col_name == 'rating':\n",
        "        new_spark_ratings_df = new_spark_ratings_df.withColumn(col_name, new_spark_ratings_df[col_name].cast('float'))\n",
        "    else:\n",
        "        new_spark_ratings_df = new_spark_ratings_df.withColumn(col_name, new_spark_ratings_df[col_name].cast('int'))\n",
        "new_spark_ratings_df.show()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "|     2| 112552|   5.0|1436165496|\n",
            "|     2| 112556|   4.0|1436165499|\n",
            "|     3|    356|   4.0| 920587155|\n",
            "|     3|   2394|   4.0| 920586920|\n",
            "|     3|   2431|   5.0| 920586945|\n",
            "|     3|   2445|   4.0| 920586945|\n",
            "|     4|     16|   4.0|1037740142|\n",
            "|     4|     39|   4.0|1037740562|\n",
            "|     4|     45|   4.0|1037808019|\n",
            "|     4|     47|   2.0|1037739998|\n",
            "|     4|     94|   5.0|1037740486|\n",
            "|     4|    101|   4.0|1037737327|\n",
            "|     4|    246|   4.0|1037739164|\n",
            "|     4|    288|   2.0|1037737415|\n",
            "|     4|    296|   4.0|1037741922|\n",
            "+------+-------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjckwl-uwcBg",
        "colab_type": "text"
      },
      "source": [
        "Let's confirm that the column data types have been changed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_D6RYmWuyEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4ce15904-341c-42f4-f512-15d5201057d2"
      },
      "source": [
        "new_spark_ratings_df.printSchema()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: float (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXUHjTpwoF4",
        "colab_type": "text"
      },
      "source": [
        "Let's print out the min() rating.<br>\n",
        "The code below creates a GroupedData object (so you can use the .min() method), then it finds the minimum value in the specified column, and returns it as a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV9WKa32wsJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "44f0dedf-2a80-4ef9-e518-d639a09d738b"
      },
      "source": [
        "new_spark_ratings_df.groupBy().min('rating').show()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|min(rating)|\n",
            "+-----------+\n",
            "|        0.5|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMyCWFn14BK",
        "colab_type": "text"
      },
      "source": [
        "## DataCamp Aggregating II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOwvLXVO195h",
        "colab_type": "text"
      },
      "source": [
        "Use the .avg() method to get the average movie_rating where the userId == 4 and movieId > 100. show() the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJlXM0n65eAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e826853c-0a22-4508-9f21-56ae5b8ec42c"
      },
      "source": [
        "new_spark_ratings_df.filter(new_spark_ratings_df.userId == 4).filter(new_spark_ratings_df.movieId > 100).groupby().avg('rating').show()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|       avg(rating)|\n",
            "+------------------+\n",
            "|3.7275280898876404|\n",
            "+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpwlhrdgApWr",
        "colab_type": "text"
      },
      "source": [
        "Let's download the dtf-flights data set. But first let's remove any such data set if it exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG0rJaVXANBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7037ea13-7bbc-4bed-ef3b-eed73f679a91"
      },
      "source": [
        "!rm dft-flights-data-2011.csv -f\n",
        "!wget https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/236265/dft-flights-data-2011.csv"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 19:32:06--  https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/236265/dft-flights-data-2011.csv\n",
            "Resolving www.gov.uk (www.gov.uk)... 151.101.0.144, 151.101.64.144, 151.101.128.144, ...\n",
            "Connecting to www.gov.uk (www.gov.uk)|151.101.0.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/236265/dft-flights-data-2011.csv [following]\n",
            "--2020-01-31 19:32:06--  https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/236265/dft-flights-data-2011.csv\n",
            "Resolving assets.publishing.service.gov.uk (assets.publishing.service.gov.uk)... 151.101.0.144, 151.101.64.144, 151.101.128.144, ...\n",
            "Connecting to assets.publishing.service.gov.uk (assets.publishing.service.gov.uk)|151.101.0.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 286257 (280K) [text/csv]\n",
            "Saving to: ‘dft-flights-data-2011.csv’\n",
            "\n",
            "\r          dft-fligh   0%[                    ]       0  --.-KB/s               \rdft-flights-data-20 100%[===================>] 279.55K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-01-31 19:32:06 (13.8 MB/s) - ‘dft-flights-data-2011.csv’ saved [286257/286257]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yljyf3sA3E5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "09796e93-923a-42be-cd71-f0ebedba3a4f"
      },
      "source": [
        "# Let's read it to a spark data frame\n",
        "dtf_flights_data = spark.read.csv('dft-flights-data-2011.csv', header=True)\n",
        "dtf_flights_data.show(10)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-------------------+------------+-----------------------+-----------+-------------------+--------------------+---------------+\n",
            "|            Customer|Number of Travellers| Total Cost ex VAT |Travel Class|Ticket Single or Return|Travel Date|Journey Start Point|Journey Finish Point|    Air Carrier|\n",
            "+--------------------+--------------------+-------------------+------------+-----------------------+-----------+-------------------+--------------------+---------------+\n",
            "|Department for Tr...|                   1|             �81.52|     ECONOMY|                 Return|  10/2/2011|            GLASGOW|        LONDON - LGW|          FLYBE|\n",
            "|Department for Tr...|                   1|            �217.14|     ECONOMY|                 Return|  29/3/2011|       LONDON - LGW|           MARRAKECH|        EASYJET|\n",
            "|Department for Tr...|                   1|          �7,969.20|    BUSINESS|                 Return|   7/4/2011|       LONDON - LHR|           SINGAPORE|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|            �272.82|    BUSINESS|                 Return|   7/4/2011|       LONDON - LGW|           EDINBURGH|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|          �7,969.20|    BUSINESS|                 Return|   7/4/2011|       LONDON - LHR|           SINGAPORE|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|            �387.60|     ECONOMY|                 Return|   8/4/2011|       LONDON - LHR|      MILAN - LINATE|       ALITALIA|\n",
            "|Department for Tr...|                   1|            �206.03|     ECONOMY|                 Return|   9/4/2011|        SOUTHAMPTON|          MANCHESTER|          FLYBE|\n",
            "|Department for Tr...|                   1|            �278.80|     ECONOMY|                 Return|  10/4/2011|       LONDON - LHR|          MANCHESTER|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|            �278.80|     ECONOMY|                 Return|  10/4/2011|       LONDON - LHR|          MANCHESTER|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|            �214.68|     ECONOMY|                 Return|  12/4/2011|       LONDON - LHR|              DUBLIN|     AER LINGUS|\n",
            "+--------------------+--------------------+-------------------+------------+-----------------------+-----------+-------------------+--------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0L8lbVPBUVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "986c1f05-b7ce-4eee-8405-90a2ced3766d"
      },
      "source": [
        "# Lets's print the schema\n",
        "dtf_flights_data.printSchema()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Customer: string (nullable = true)\n",
            " |-- Number of Travellers: string (nullable = true)\n",
            " |--  Total Cost ex VAT : string (nullable = true)\n",
            " |-- Travel Class: string (nullable = true)\n",
            " |-- Ticket Single or Return: string (nullable = true)\n",
            " |-- Travel Date: string (nullable = true)\n",
            " |-- Journey Start Point: string (nullable = true)\n",
            " |-- Journey Finish Point: string (nullable = true)\n",
            " |-- Air Carrier: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvde8PTmBkrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e471ba94-2d2d-440b-dd2b-2012deb4eab2"
      },
      "source": [
        "dtf_flights_data.columns"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Customer',\n",
              " 'Number of Travellers',\n",
              " ' Total Cost ex VAT ',\n",
              " 'Travel Class',\n",
              " 'Ticket Single or Return',\n",
              " 'Travel Date',\n",
              " 'Journey Start Point',\n",
              " 'Journey Finish Point',\n",
              " 'Air Carrier']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGSgSIOZCstl",
        "colab_type": "text"
      },
      "source": [
        "Some column headers have unncessary spaces. let's clean it up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWDFyfy4FRug",
        "colab_type": "text"
      },
      "source": [
        "Let's change to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPKP-I4NEmvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5dbd5296-ad5b-47fc-8da7-6692f743cd5e"
      },
      "source": [
        "# Let's change it to a pandas column and clean out the column names\n",
        "dtf_flights_data = dtf_flights_data.toPandas()\n",
        "dtf_flights_data.head()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer</th>\n",
              "      <th>Number of Travellers</th>\n",
              "      <th>Total Cost ex VAT</th>\n",
              "      <th>Travel Class</th>\n",
              "      <th>Ticket Single or Return</th>\n",
              "      <th>Travel Date</th>\n",
              "      <th>Journey Start Point</th>\n",
              "      <th>Journey Finish Point</th>\n",
              "      <th>Air Carrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�81.52</td>\n",
              "      <td>ECONOMY</td>\n",
              "      <td>Return</td>\n",
              "      <td>10/2/2011</td>\n",
              "      <td>GLASGOW</td>\n",
              "      <td>LONDON - LGW</td>\n",
              "      <td>FLYBE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�217.14</td>\n",
              "      <td>ECONOMY</td>\n",
              "      <td>Return</td>\n",
              "      <td>29/3/2011</td>\n",
              "      <td>LONDON - LGW</td>\n",
              "      <td>MARRAKECH</td>\n",
              "      <td>EASYJET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�7,969.20</td>\n",
              "      <td>BUSINESS</td>\n",
              "      <td>Return</td>\n",
              "      <td>7/4/2011</td>\n",
              "      <td>LONDON - LHR</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>BRITISH AIRWAYS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�272.82</td>\n",
              "      <td>BUSINESS</td>\n",
              "      <td>Return</td>\n",
              "      <td>7/4/2011</td>\n",
              "      <td>LONDON - LGW</td>\n",
              "      <td>EDINBURGH</td>\n",
              "      <td>BRITISH AIRWAYS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�7,969.20</td>\n",
              "      <td>BUSINESS</td>\n",
              "      <td>Return</td>\n",
              "      <td>7/4/2011</td>\n",
              "      <td>LONDON - LHR</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>BRITISH AIRWAYS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Customer  ...      Air Carrier\n",
              "0  Department for Transport  ...            FLYBE\n",
              "1  Department for Transport  ...          EASYJET\n",
              "2  Department for Transport  ...  BRITISH AIRWAYS\n",
              "3  Department for Transport  ...  BRITISH AIRWAYS\n",
              "4  Department for Transport  ...  BRITISH AIRWAYS\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUk2N1KxC35U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = ['Customer','Number_of_Travellers','Total_Cost_ex_VAT','Travel_Class','Ticket_Single_or_Return', 'Travel_Date',\n",
        "           'Journey_Start_Point','Journey_Finish_Point','Air_Carrier']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfEoOg-xDydv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "27545780-162c-4374-eee1-30129ca825f7"
      },
      "source": [
        "# Let's make the column headers, headers\n",
        "dtf_flights_data.columns = headers\n",
        "dtf_flights_data.head(3)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer</th>\n",
              "      <th>Number_of_Travellers</th>\n",
              "      <th>Total_Cost_ex_VAT</th>\n",
              "      <th>Travel_Class</th>\n",
              "      <th>Ticket_Single_or_Return</th>\n",
              "      <th>Travel_Date</th>\n",
              "      <th>Journey_Start_Point</th>\n",
              "      <th>Journey_Finish_Point</th>\n",
              "      <th>Air_Carrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�81.52</td>\n",
              "      <td>ECONOMY</td>\n",
              "      <td>Return</td>\n",
              "      <td>10/2/2011</td>\n",
              "      <td>GLASGOW</td>\n",
              "      <td>LONDON - LGW</td>\n",
              "      <td>FLYBE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�217.14</td>\n",
              "      <td>ECONOMY</td>\n",
              "      <td>Return</td>\n",
              "      <td>29/3/2011</td>\n",
              "      <td>LONDON - LGW</td>\n",
              "      <td>MARRAKECH</td>\n",
              "      <td>EASYJET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Department for Transport</td>\n",
              "      <td>1</td>\n",
              "      <td>�7,969.20</td>\n",
              "      <td>BUSINESS</td>\n",
              "      <td>Return</td>\n",
              "      <td>7/4/2011</td>\n",
              "      <td>LONDON - LHR</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>BRITISH AIRWAYS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Customer  ...      Air_Carrier\n",
              "0  Department for Transport  ...            FLYBE\n",
              "1  Department for Transport  ...          EASYJET\n",
              "2  Department for Transport  ...  BRITISH AIRWAYS\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkRoyX12Pt8I",
        "colab_type": "text"
      },
      "source": [
        "Next let's clean the Total_Cost_ex-VAT column, removing the question mark in front and any commas,then converting to a float, then we convert the number of travellers column to an int8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-zlAk6AP116",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtf_flights_data['Total_Cost_ex_VAT'] = dtf_flights_data['Total_Cost_ex_VAT'].apply(lambda x: x[1:]).apply(lambda x: x.replace(',',''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvPyd_k4Qrdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtf_flights_data = dtf_flights_data.astype({'Total_Cost_ex_VAT':'float', 'Number_of_Travellers':'int8'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgG_BmPCTGnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d2ab23c3-eae5-4dab-8355-9fbf7bf5463e"
      },
      "source": [
        "dtf_flights_data.dtypes"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Customer                    object\n",
              "Number_of_Travellers          int8\n",
              "Total_Cost_ex_VAT          float64\n",
              "Travel_Class                object\n",
              "Ticket_Single_or_Return     object\n",
              "Travel_Date                 object\n",
              "Journey_Start_Point         object\n",
              "Journey_Finish_Point        object\n",
              "Air_Carrier                 object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfQNdrDZU6Pt",
        "colab_type": "text"
      },
      "source": [
        "Let's convert the cleaned table to a Spark data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtWrkZE-U-1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2b504208-14b3-42ee-cf1b-f6511d02dda2"
      },
      "source": [
        "spark_dtf_flights_df = spark.createDataFrame(dtf_flights_data)\n",
        "spark_dtf_flights_df.show(5)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----------------+------------+-----------------------+-----------+-------------------+--------------------+---------------+\n",
            "|            Customer|Number_of_Travellers|Total_Cost_ex_VAT|Travel_Class|Ticket_Single_or_Return|Travel_Date|Journey_Start_Point|Journey_Finish_Point|    Air_Carrier|\n",
            "+--------------------+--------------------+-----------------+------------+-----------------------+-----------+-------------------+--------------------+---------------+\n",
            "|Department for Tr...|                   1|            81.52|     ECONOMY|                 Return|  10/2/2011|            GLASGOW|        LONDON - LGW|          FLYBE|\n",
            "|Department for Tr...|                   1|           217.14|     ECONOMY|                 Return|  29/3/2011|       LONDON - LGW|           MARRAKECH|        EASYJET|\n",
            "|Department for Tr...|                   1|           7969.2|    BUSINESS|                 Return|   7/4/2011|       LONDON - LHR|           SINGAPORE|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|           272.82|    BUSINESS|                 Return|   7/4/2011|       LONDON - LGW|           EDINBURGH|BRITISH AIRWAYS|\n",
            "|Department for Tr...|                   1|           7969.2|    BUSINESS|                 Return|   7/4/2011|       LONDON - LHR|           SINGAPORE|BRITISH AIRWAYS|\n",
            "+--------------------+--------------------+-----------------+------------+-----------------------+-----------+-------------------+--------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T4oz-zeVRVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "cdd4eb86-9d21-4220-8938-5d8bec38c9ee"
      },
      "source": [
        "spark_dtf_flights_df.printSchema()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Customer: string (nullable = true)\n",
            " |-- Number_of_Travellers: long (nullable = true)\n",
            " |-- Total_Cost_ex_VAT: double (nullable = true)\n",
            " |-- Travel_Class: string (nullable = true)\n",
            " |-- Ticket_Single_or_Return: string (nullable = true)\n",
            " |-- Travel_Date: string (nullable = true)\n",
            " |-- Journey_Start_Point: string (nullable = true)\n",
            " |-- Journey_Finish_Point: string (nullable = true)\n",
            " |-- Air_Carrier: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuD27ZcmVQGm",
        "colab_type": "text"
      },
      "source": [
        "Use the .sum() method to get the total cost excluding VAT, where the Air_Carrier is British Airways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3p0Ote3V_jw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ce98c79f-a7ad-4954-b633-8488711185fc"
      },
      "source": [
        "spark_dtf_flights_df.filter(spark_dtf_flights_df.Air_Carrier == 'BRITISH AIRWAYS').groupby().sum('Total_Cost_ex_VAT').show()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|sum(Total_Cost_ex_VAT)|\n",
            "+----------------------+\n",
            "|    484898.04999999906|\n",
            "+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKRcLhYYXPsH",
        "colab_type": "text"
      },
      "source": [
        "Use the .sum() method to get the total cost excluding VAT, where the travel class is business class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QP2CAapXQgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e6918d81-3ab0-4ba2-ccb7-74d635bb364e"
      },
      "source": [
        "spark_dtf_flights_df.filter(spark_dtf_flights_df.Travel_Class == 'BUSINESS').groupby().sum('Total_Cost_ex_VAT').show()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|sum(Total_Cost_ex_VAT)|\n",
            "+----------------------+\n",
            "|     696179.6199999996|\n",
            "+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx9Cj1FsZ7QQ",
        "colab_type": "text"
      },
      "source": [
        "Let's add the spark_flights df as a temporary table in our session catalog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_fzH6LFaEAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark_dtf_flights_df.createOrReplaceTempView('spark_dtf_flights_table')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLxDmW9cZlGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "8a705a99-3f54-4b47-a787-6ecd1d30d873"
      },
      "source": [
        "spark.catalog.listTables()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='spark_dtf_flights_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='spark_links_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='spark_ratings_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='spark_tags_df', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='temp_movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='world_bank', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nmvk1vbcd50",
        "colab_type": "text"
      },
      "source": [
        "## DataCamp Grouping and Aggregating I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZtgEbBY8lBO",
        "colab_type": "text"
      },
      "source": [
        "PySpark has a whole class devoted to grouped data frames: pyspark.sql.GroupedData, which you saw in the last two exercises.\n",
        "\n",
        "You've learned how to create a grouped DataFrame by calling the .groupBy() method on a DataFrame with no arguments.\n",
        "\n",
        "Now you'll see that when you pass the name of one or more columns in your DataFrame to the .groupBy() method, the aggregation methods behave like when you use a GROUP BY statement in a SQL query!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjLimYLZolA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "4e3f5df7-9849-4ee3-a987-78e106e3e556"
      },
      "source": [
        "# Groupby Travel_Class\n",
        "by_class = spark_dtf_flights_df.groupBy('Travel_Class')\n",
        "by_class.count().show()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+-----+\n",
            "|   Travel_Class|count|\n",
            "+---------------+-----+\n",
            "|       BUSINESS|  420|\n",
            "|        ECONOMY| 2465|\n",
            "|PREMIUM ECONOMY|   61|\n",
            "|          FIRST|    9|\n",
            "+---------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDgNbhVq-czb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "f9fe8e6d-9863-431e-f9d6-091c925f568a"
      },
      "source": [
        "# Groupby Air_Carrier\n",
        "by_carrier = spark_dtf_flights_df.groupBy('Air_Carrier')\n",
        "by_carrier.count().show()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|         Air_Carrier|count|\n",
            "+--------------------+-----+\n",
            "|          AIR CANADA|   27|\n",
            "|     EASTERN AIRWAYS|  183|\n",
            "|            ALITALIA|    7|\n",
            "|             EASYJET|  242|\n",
            "|          AIR FRANCE|   58|\n",
            "|    CROATIA AIRLINES|    1|\n",
            "|     BRITISH MIDLAND|  106|\n",
            "|             WIZZAIR|    9|\n",
            "|     ICELAND AIRWAYS|    1|\n",
            "|          AIR BERLIN|    2|\n",
            "|      MISC SUPPLIERS|    5|\n",
            "|KINGFISHER AIRLIN...|    3|\n",
            "|               JET 2|    2|\n",
            "|CONTINENTAL AIRLINES|    4|\n",
            "|     VIRGIN ATLANTIC|   39|\n",
            "|                MANX|    4|\n",
            "|     CIMBER STERLING|    2|\n",
            "|SOUTH AFRICAN AIR...|    3|\n",
            "|   AER ARANN EXPRESS|    1|\n",
            "|           LUFTHANSA|   31|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCX_7pwX_Bqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "42230d1f-3906-423c-8377-5cc4f2d7fc85"
      },
      "source": [
        "# Groupby tickets\n",
        "by_ticket = spark_dtf_flights_df.groupBy('Ticket_Single_or_Return')\n",
        "by_ticket.count().show()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-----+\n",
            "|Ticket_Single_or_Return|count|\n",
            "+-----------------------+-----+\n",
            "|                 Return| 2145|\n",
            "|                 Single|  810|\n",
            "+-----------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRfaQuWJ_ntz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "79242a87-5066-4513-dc69-1f7af7da434f"
      },
      "source": [
        "# Find average total cost excluding VAT for ticket types\n",
        "by_ticket.avg('Total_Cost_ex_VAT').show()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+----------------------+\n",
            "|Ticket_Single_or_Return|avg(Total_Cost_ex_VAT)|\n",
            "+-----------------------+----------------------+\n",
            "|                 Return|     583.4886480186494|\n",
            "|                 Single|    183.18604938271622|\n",
            "+-----------------------+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pETLlkKAUZn",
        "colab_type": "text"
      },
      "source": [
        "## DataCamp Grouping and Aggregating II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbZWMm3BdsP",
        "colab_type": "text"
      },
      "source": [
        "In addition to the GroupedData methods you've already seen, there is also the .agg() method. This method lets you pass an aggregate column expression that uses any of the aggregate functions from the pyspark.sql.functions submodule.\n",
        "\n",
        "This submodule contains many useful functions for computing things like standard deviations. All the aggregation functions in this submodule take the name of a column in a GroupedData table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJn5Yd1-AXmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC6SOtTbCJrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Groupby Travel_Class and Air_Carrier\n",
        "by_travel_carrier = spark_dtf_flights_df.groupBy('Travel_Class','Air_Carrier')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu9yhJjFC_Re",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "36be0440-72fc-49b7-c151-9c942ffa03bc"
      },
      "source": [
        "# Get the average total cost excluding VAt by Travel_Class and Air_Carrier\n",
        "by_travel_carrier.avg('Total_Cost_ex_VAT').show()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+--------------------+----------------------+\n",
            "|   Travel_Class|         Air_Carrier|avg(Total_Cost_ex_VAT)|\n",
            "+---------------+--------------------+----------------------+\n",
            "|        ECONOMY|               JET 2|               174.845|\n",
            "|PREMIUM ECONOMY|            ALITALIA|                  64.6|\n",
            "|       BUSINESS|            EMIRATES|    1991.1333333333332|\n",
            "|       BUSINESS|     BRITISH MIDLAND|     780.1386666666668|\n",
            "|        ECONOMY|SN BRUSSELS AIRLINES|                 406.5|\n",
            "|       BUSINESS|             FINNAIR|    1276.7642857142857|\n",
            "|        ECONOMY|             WIZZAIR|     90.05777777777777|\n",
            "|        ECONOMY| LOT POLISH AIRLINES|                288.65|\n",
            "|        ECONOMY|           AIR MALTA|                 455.7|\n",
            "|       BUSINESS| TAM - LINHAS AEREAS|                1050.2|\n",
            "|        ECONOMY|      CYPRUS AIRWAYS|                 152.7|\n",
            "|PREMIUM ECONOMY|     BRITISH AIRWAYS|               2271.97|\n",
            "|        ECONOMY|CHINA EASTERN AIR...|    386.41999999999996|\n",
            "|       BUSINESS| HAHN AIR LINES GMBH|                 241.9|\n",
            "|        ECONOMY|     EASTERN AIRWAYS|     282.0920454545458|\n",
            "|        ECONOMY|   MALEV - HUNGARIAN|                 440.6|\n",
            "|        ECONOMY|AURIGNY AIR SERVICES|     85.13866666666667|\n",
            "|        ECONOMY|DO NOT USE - EASY...|                146.22|\n",
            "|        ECONOMY|    MONARCH AIRLINES|    189.64999999999998|\n",
            "|       BUSINESS|                 KLM|      1580.27137254902|\n",
            "+---------------+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRefRE7wEWPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "26c226fc-6271-490c-fae1-8c52cba02158"
      },
      "source": [
        "by_travel_carrier.agg(F.stddev('Total_Cost_ex_VAT')).show()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+--------------------+------------------------------+\n",
            "|   Travel_Class|         Air_Carrier|stddev_samp(Total_Cost_ex_VAT)|\n",
            "+---------------+--------------------+------------------------------+\n",
            "|        ECONOMY|               JET 2|            129.88844463615692|\n",
            "|PREMIUM ECONOMY|            ALITALIA|                           NaN|\n",
            "|       BUSINESS|            EMIRATES|             500.9058461094927|\n",
            "|       BUSINESS|     BRITISH MIDLAND|             505.7784452542532|\n",
            "|        ECONOMY|SN BRUSSELS AIRLINES|            330.88973238829885|\n",
            "|       BUSINESS|             FINNAIR|             965.4667837865983|\n",
            "|        ECONOMY|             WIZZAIR|             27.20542398942616|\n",
            "|        ECONOMY| LOT POLISH AIRLINES|             81.24656915833434|\n",
            "|        ECONOMY|           AIR MALTA|             44.12346314604055|\n",
            "|       BUSINESS| TAM - LINHAS AEREAS|                           0.0|\n",
            "|        ECONOMY|      CYPRUS AIRWAYS|                           NaN|\n",
            "|PREMIUM ECONOMY|     BRITISH AIRWAYS|              642.733282821933|\n",
            "|        ECONOMY|CHINA EASTERN AIR...|            222.51389170116994|\n",
            "|       BUSINESS| HAHN AIR LINES GMBH|                           NaN|\n",
            "|        ECONOMY|     EASTERN AIRWAYS|              98.5731296004179|\n",
            "|        ECONOMY|   MALEV - HUNGARIAN|                           NaN|\n",
            "|        ECONOMY|AURIGNY AIR SERVICES|            43.168734364892686|\n",
            "|        ECONOMY|DO NOT USE - EASY...|            120.13989442867567|\n",
            "|        ECONOMY|    MONARCH AIRLINES|            189.24776643331882|\n",
            "|       BUSINESS|                 KLM|             863.8649936767192|\n",
            "+---------------+--------------------+------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRkSQukMGSFb",
        "colab_type": "text"
      },
      "source": [
        "## DataCamp Joining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603Q2-UlGYii",
        "colab_type": "text"
      },
      "source": [
        "A join will combine two different tables along a column that they share. This column is called the key. Examples of keys here include the Journey start point or the movieId column in the movies dataset.\n",
        "\n",
        "**Joining II**\n",
        "\n",
        "In PySpark, joins are performed using the DataFrame method .join(). This method takes three arguments. The first is the second DataFrame that you want to join with the first one. The second argument, on, is the name of the key column(s) as a string. The names of the key column(s) must be the same in each table. The third argument, how, specifies the kind of join to perform. In this course we'll always use the value how=\"leftouter\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URfRGnctP6o0",
        "colab_type": "text"
      },
      "source": [
        "Let's define the spark_movies_df from the pandas movies_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8FfsNQHHN_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "010be0a6-e0dc-45c9-bd70-1f05e47991ac"
      },
      "source": [
        "spark_movies_df = spark.createDataFrame(movies_df)\n",
        "spark_movies_df.show(5)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMu1R4qdP0Oz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6306ddc1-69a8-4bea-98cb-3c11e56ea9ea"
      },
      "source": [
        "spark_movies_df.count()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN6Mucl5QC3B",
        "colab_type": "text"
      },
      "source": [
        "Let's see the new_spark_ratings_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T64t3wW8JJEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e2fed794-5384-40a4-ad15-cd93afe4bc6d"
      },
      "source": [
        "new_spark_ratings_df.show(5)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPynnR0yPnn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21541185-5097-4ea8-b269-8facfd5accb2"
      },
      "source": [
        "new_spark_ratings_df.count()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22884377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg6DNDbLKh_y",
        "colab_type": "text"
      },
      "source": [
        "Renaming a Column name in pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Ej49WfKn4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "45f6d0aa-1c76-4ca6-920f-d210017972b8"
      },
      "source": [
        "# I can rename the timestamp col of new_spark_ratings_df by using the .withColumnRenamed() func.\n",
        "new_spark_ratings_df = new_spark_ratings_df.withColumnRenamed('timestamp', 'time')\n",
        "# first pass the column name, then the renamed name in second place.\n",
        "new_spark_ratings_df.show(5)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating|      time|\n",
            "+------+-------+------+----------+\n",
            "|     1|    169|   2.5|1204927694|\n",
            "|     1|   2471|   3.0|1204927438|\n",
            "|     1|  48516|   5.0|1204927435|\n",
            "|     2|   2571|   3.5|1436165433|\n",
            "|     2| 109487|   4.0|1436165496|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdHUvWlwNBv6",
        "colab_type": "text"
      },
      "source": [
        "Join both new_spark_ratings_df and spark_movies_df on column movieId.<br>\n",
        "call the .join() method on the new_spark_ratings_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SS9XHhbNUjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "388b2087-00e7-4a55-caaa-6a47de360d75"
      },
      "source": [
        "spark_movies_ratings_df = new_spark_ratings_df.join(spark_movies_df, on='movieId', how='left_outer')\n",
        "spark_movies_ratings_df.show(5)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------+----------+--------------+------+\n",
            "|movieId|userId|rating|      time|         title|genres|\n",
            "+-------+------+------+----------+--------------+------+\n",
            "|     26|    38|   3.5|1228039312|Othello (1995)| Drama|\n",
            "|     26|   114|   3.0|1003527162|Othello (1995)| Drama|\n",
            "|     26|   407|   3.5|1118267047|Othello (1995)| Drama|\n",
            "|     26|   447|   2.5|1326528578|Othello (1995)| Drama|\n",
            "|     26|   503|   3.0|1216156573|Othello (1995)| Drama|\n",
            "+-------+------+------+----------+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVDGFRO3QKKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d58f84e7-e2c4-4855-fc0f-0a9b80127239"
      },
      "source": [
        "spark_movies_ratings_df.count()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22884377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EVxdvSWPODm",
        "colab_type": "text"
      },
      "source": [
        "Notice that automatically, the movieId column becomes the first column.<br>\n",
        "This is because it is the key of the join command. Both tables are joined on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfYg0y-gPcOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}